{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimenision of the original dataset is  (595212, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "id                                                                              \n",
       "7        0          2              2          5              1              0   \n",
       "9        0          1              1          7              0              0   \n",
       "13       0          5              4          9              1              0   \n",
       "16       0          0              1          2              0              0   \n",
       "17       0          0              2          0              1              0   \n",
       "\n",
       "    ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  \\\n",
       "id                                                               \n",
       "7               0              1              0              0   \n",
       "9               0              0              1              0   \n",
       "13              0              0              1              0   \n",
       "16              1              0              0              0   \n",
       "17              1              0              0              0   \n",
       "\n",
       "         ...        ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  \\\n",
       "id       ...                                                         \n",
       "7        ...                 9           1           5           8   \n",
       "9        ...                 3           1           1           9   \n",
       "13       ...                 4           2           7           7   \n",
       "16       ...                 2           2           4           9   \n",
       "17       ...                 3           1           1           3   \n",
       "\n",
       "    ps_calc_15_bin  ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  \\\n",
       "id                                                                   \n",
       "7                0               1               1               0   \n",
       "9                0               1               1               0   \n",
       "13               0               1               1               0   \n",
       "16               0               0               0               0   \n",
       "17               0               0               0               1   \n",
       "\n",
       "    ps_calc_19_bin  ps_calc_20_bin  \n",
       "id                                  \n",
       "7                0               1  \n",
       "9                1               0  \n",
       "13               1               0  \n",
       "16               0               0  \n",
       "17               1               0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"./Desktop/Depaul/csc529/Homework/Final Project/train.csv\")\n",
    "df = pd.read_csv(\"./train2.csv\")\n",
    "df = df.set_index(\"id\")\n",
    "print(\"The dimenision of the original dataset is \",df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B   C\n",
       "0  1  3   5\n",
       "1 -1  9  19"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play = pd.DataFrame(list(zip([1,-1,2],[3,9,8],[5,19,-1])), columns=(\"A\",\"B\",\"C\"))\n",
    "play = play[play.loc[:,\"C\"]!=-1]\n",
    "play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target (0, 58)\n",
      "ps_ind_01 (0, 58)\n",
      "ps_ind_02_cat (0, 58)\n",
      "ps_ind_03 (0, 58)\n",
      "ps_ind_04_cat (0, 58)\n",
      "ps_ind_05_cat (0, 58)\n",
      "ps_ind_06_bin (0, 58)\n",
      "ps_ind_07_bin (0, 58)\n",
      "ps_ind_08_bin (0, 58)\n",
      "ps_ind_09_bin (0, 58)\n",
      "ps_ind_10_bin (0, 58)\n",
      "ps_ind_11_bin (0, 58)\n",
      "ps_ind_12_bin (0, 58)\n",
      "ps_ind_13_bin (0, 58)\n",
      "ps_ind_14 (0, 58)\n",
      "ps_ind_15 (0, 58)\n",
      "ps_ind_16_bin (0, 58)\n",
      "ps_ind_17_bin (0, 58)\n",
      "ps_ind_18_bin (0, 58)\n",
      "ps_reg_01 (0, 58)\n",
      "ps_reg_02 (0, 58)\n",
      "ps_reg_03 (0, 58)\n",
      "ps_car_01_cat (0, 58)\n",
      "ps_car_02_cat (0, 58)\n",
      "ps_car_03_cat (0, 58)\n",
      "ps_car_04_cat (0, 58)\n",
      "ps_car_05_cat (0, 58)\n",
      "ps_car_06_cat (0, 58)\n",
      "ps_car_07_cat (0, 58)\n",
      "ps_car_08_cat (0, 58)\n",
      "ps_car_09_cat (0, 58)\n",
      "ps_car_10_cat (0, 58)\n",
      "ps_car_11_cat (0, 58)\n",
      "ps_car_11 (0, 58)\n",
      "ps_car_12 (0, 58)\n",
      "ps_car_13 (0, 58)\n",
      "ps_car_14 (0, 58)\n",
      "ps_car_15 (0, 58)\n",
      "ps_calc_01 (0, 58)\n",
      "ps_calc_02 (0, 58)\n",
      "ps_calc_03 (0, 58)\n",
      "ps_calc_04 (0, 58)\n",
      "ps_calc_05 (0, 58)\n",
      "ps_calc_06 (0, 58)\n",
      "ps_calc_07 (0, 58)\n",
      "ps_calc_08 (0, 58)\n",
      "ps_calc_09 (0, 58)\n",
      "ps_calc_10 (0, 58)\n",
      "ps_calc_11 (0, 58)\n",
      "ps_calc_12 (0, 58)\n",
      "ps_calc_13 (0, 58)\n",
      "ps_calc_14 (0, 58)\n",
      "ps_calc_15_bin (0, 58)\n",
      "ps_calc_16_bin (0, 58)\n",
      "ps_calc_17_bin (0, 58)\n",
      "ps_calc_18_bin (0, 58)\n",
      "ps_calc_19_bin (0, 58)\n",
      "ps_calc_20_bin (0, 58)\n"
     ]
    }
   ],
   "source": [
    "col_index_lst=list(df2.columns)\n",
    "for col_name in col_index_lst:\n",
    "    print(\"%s %s\"% (col_name,df2[df2.loc[:,col_name]==-1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "for col_name in col_index_lst:\n",
    "    df3 = df3[df3.loc[:,col_name] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.346099760217401"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.ps_car_11[df3.ps_car_11.value_counts().max()]\n",
    "\n",
    "#pd.DataFrame(df.ps_car_02_cat[df.ps_car_02_cat != -1].value_counts()).reset_index()\n",
    "df2.loc[:,\"ps_car_11\"][df2.loc[:,\"ps_car_11\"] != -1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    5\n",
       "Name: ps_car_11, dtype: int64"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,\"ps_car_11\"][df.loc[:,\"ps_car_11\"] == -1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "334459    -1.0\n",
       "356241    -1.0\n",
       "567304    -1.0\n",
       "1185902   -1.0\n",
       "1333531   -1.0\n",
       "Name: ps_car_11, dtype: float64"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[:,\"ps_car_11\"][df2.loc[:,\"ps_car_11\"] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "df2=df\n",
    "df2.loc[:,\"ps_ind_02_cat\"][df2.loc[:,\"ps_ind_02_cat\"] == -1] = pd.DataFrame(df2.ps_ind_02_cat[df2.ps_ind_02_cat != -1].value_counts()).reset_index().loc[0,\"index\"]\n",
    "df2.loc[:,\"ps_ind_04_cat\"][df2.loc[:,\"ps_ind_04_cat\"] == -1] = pd.DataFrame(df2.ps_ind_02_cat[df2.ps_ind_02_cat != -1].value_counts()).reset_index().loc[0,\"index\"]\n",
    "df2.loc[:,\"ps_ind_05_cat\"][df2.loc[:,\"ps_ind_05_cat\"] == -1] = pd.DataFrame(df2.ps_ind_05_cat[df2.ps_ind_05_cat != -1].value_counts()).reset_index().loc[0,\"index\"]\n",
    "\n",
    "df2.loc[:,\"ps_reg_03\"][df2.loc[:,\"ps_reg_03\"]==-1] = df2.loc[:,\"ps_reg_03\"][df2.loc[:,\"ps_reg_03\"] != -1].mean()\n",
    "df2.loc[:,\"ps_car_01_cat\"][df2.loc[:,\"ps_car_01_cat\"] == -1] = pd.DataFrame(df2.ps_car_01_cat[df2.ps_car_01_cat != -1].value_counts()).reset_index().loc[0,\"index\"]\n",
    "df2.loc[:,\"ps_car_02_cat\"][df2.loc[:,\"ps_car_02_cat\"] == -1] = pd.DataFrame(df2.ps_car_02_cat[df2.ps_car_02_cat != -1].value_counts()).reset_index().loc[0,\"index\"]\n",
    "df2.loc[:,\"ps_car_03_cat\"][df2.loc[:,\"ps_car_03_cat\"] == -1] = pd.DataFrame(df2.ps_car_03_cat[df2.ps_car_03_cat != -1].value_counts()).reset_index().loc[0,\"index\"]\n",
    "df2.loc[:,\"ps_car_05_cat\"][df2.loc[:,\"ps_car_05_cat\"] == -1] = pd.DataFrame(df2.ps_car_05_cat[df2.ps_car_05_cat != -1].value_counts()).reset_index().loc[0,\"index\"]\n",
    "df2.loc[:,\"ps_car_07_cat\"][df2.loc[:,\"ps_car_07_cat\"] == -1] = pd.DataFrame(df2.ps_car_07_cat[df2.ps_car_07_cat != -1].value_counts()).reset_index().loc[0,\"index\"]\n",
    "df2.loc[:,\"ps_car_09_cat\"][df2.loc[:,\"ps_car_09_cat\"] == -1] = pd.DataFrame(df2.ps_car_09_cat[df2.ps_car_09_cat != -1].value_counts()).reset_index().loc[0,\"index\"]\n",
    "\n",
    "df2.loc[:,\"ps_car_11\"][df2.loc[:,\"ps_car_11\"] == -1] = df2.loc[:,\"ps_car_11\"][df2.loc[:,\"ps_car_11\"] != -1].mean()\n",
    "df2.loc[:,\"ps_car_12\"][df2.loc[:,\"ps_car_12\"] == -1] = df2.loc[:,\"ps_car_12\"][df2.loc[:,\"ps_car_12\"] != -1].mean()\n",
    "df2.loc[:,\"ps_car_14\"][df2.loc[:,\"ps_car_14\"] == -1] = df2.loc[:,\"ps_car_14\"][df2.loc[:,\"ps_car_14\"] != -1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    119261\n",
       "1      5670\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "id                                                                      \n",
       "16          0              1          2              0              0   \n",
       "22          5              1          4              0              0   \n",
       "28          1              1          2              0              0   \n",
       "\n",
       "    ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ps_ind_10_bin  \\\n",
       "id                                                                              \n",
       "16              1              0              0              0              0   \n",
       "22              1              0              0              0              0   \n",
       "28              0              1              0              0              0   \n",
       "\n",
       "         ...        ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  \\\n",
       "id       ...                                                         \n",
       "16       ...                 2           2           4           9   \n",
       "22       ...                 7           1           3           6   \n",
       "28       ...                 3           5           0           6   \n",
       "\n",
       "    ps_calc_15_bin  ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  \\\n",
       "id                                                                   \n",
       "16               0               0               0               0   \n",
       "22               1               0               1               0   \n",
       "28               0               1               0               0   \n",
       "\n",
       "    ps_calc_19_bin  ps_calc_20_bin  \n",
       "id                                  \n",
       "16               0               0  \n",
       "22               1               0  \n",
       "28               1               0  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y3 = df3.target\n",
    "X3 = df3.loc[:, \"ps_ind_01\":]\n",
    "X3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    573518\n",
      "1     21694\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5IAAAFJCAYAAADpFxLXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu0p1V9H/73R0aRREUu0wkOEEjAJmiijSeouf2MpkAu\nDaalhtycpkSaJUlzj5imwWhj9Nc2Rhu1pWq4aEVCvBAT1BGMMSuKDEZDQC0TlcDILcwIwbZU8NM/\nvnvCd45zOc8MZw4z83qt9V3n+X6evfezv2fWmlnv2c+zv9XdAQAAgKV6xEpPAAAAgH2LIAkAAMAk\ngiQAAACTCJIAAABMIkgCAAAwiSAJAADAJIIkACuuql5SVW9e6XnsSlV9rqq+Z2/3XcLY91bV1z1E\nY/1aVb1hHB9XVV1Vqx6isY8dcz3ooRgPgJUjSAKwV1TVj1bVhhEkbq2qK6rqO1ZoLl1VJ6zEtaeo\nqmdV1ZfH7+zeqrqlqi6tqm+db9fdj+nuzyxhrFt2dc3ufnl3/9Sezn1cc5vw3N1/O+b6wEMxPgAr\nR5AEYNlV1S8m+d0kL0+yJsmxSV6b5AdXcl77iM9392OSPDbJM5J8KsmHquo5D/WFHqqVRwD2f4Ik\nAMuqqg5N8tIk53T327v7i939pe5+d3f/6g76/EFV3VZVd1fVn1XVk+bOfV9V3VBVf19Vm6rql0f9\nyKp6d1V9oao2V9WHqmrSv3NV9fVVdVVV3VVVf1dVb6mqxy9q9q3j+luq6ver6tFz/X+gqj4+5vAX\nVfXNO7jOyWN19p6qur2qfmdXc+uZW7r7N5K8Ickr58b7hxXW7f1+quqrk1yR5Alzq5tPGLcUX1ZV\nb66qe5L8qx3cZvyvq+rzYyX5l+eue0FV/Ye59/+w6llVF2f2HwZ/NK73q4tvlR1zuHz8eW2sqhfM\njfWSsfp60fgs11fVwq5+TwDsHYIkAMvtmUkeneQdE/pckeTEJP8oyceSvGXu3BuT/JvufmySJye5\natR/KcktSVZntur5a0l64lwryW8neUKSb0xyTJKXLGrzY0lOTfL1SZ6Y5NeTpKr+SZI3Jfk3SY5I\n8t+SXF5VB2/nOq9O8uruftwY59KJ83x7km8ZAXGxr/j9dPcXk3xvxurmeH1+tD89yWVJHp9tf8/z\nvjuzP49TkrxoKc96dvdPJPnbJP9sXO//306zSzL7M3tCkjOSvLyqnj13/gdHm8cnuTzJ7+3qugDs\nHYIkAMvtiCR/1933L7VDd7+pu/++u+/LLMg9ZaxsJsmXkpxUVY/r7i3d/bG5+lFJvnaseH6ouycF\nye7e2N3ru/u+7r4zye8k+f8WNfu97r65uzcn+a0kPzLqZyf5b919dXc/0N0XJrkvs9tRF/tSkhOq\n6sjuvre7PzJlnkk+n1noXbxaunXs7f1+duTD3f3O7v5yd//vHbT5zbGSfF2S38+Dn3m3VdUxSb49\nyYu6+/9098czW2l9/lyzP+/uPxnPVF6c5Cl7el0AHhqCJADL7a4kRy71+buqOqiqXlFVfzNut/zc\nOHXk+Pkvknxfkpuq6oNV9cxR/49JNiZ5X1V9pqrOnTrRqlpTVZeMW0LvSfLmuetudfPc8U2ZraYl\nydcm+aVxW+sXquoLma1oPiFf6azMVjM/VVXXVNUPTJzq2sxWW7+wnXM7+v3syM27OL+4zfxn3hNP\nSLK5u/9+0dhr597fNnf8v5I82nOcAA8PgiQAy+3Dma3MPXeJ7X80s9stvyfJoUmOG/VKku6+prtP\nz+y213dm3BY6VjB/qbu/LrNbIn9xNzakeXlmAe2bxm2nP771unOOmTs+NrPVwWQWtn6rux8/9/qq\n7n7r4ot0943d/SPjM7wyyWU7uE11R34oycfGLauLx97u7yc7vs13Kau2O/rMX0zyVXPnvmbC2J9P\ncnhVPXbR2JuWMB8AVpggCcCy6u67k/xGktdW1XOr6quq6pFV9b1Vtb3n5h6bWfC8K7OQ8vKtJ6rq\nUVX1Y1V1aHd/Kck9Sb48zv1AVZ1QVZXk7iQPbD23A4+qqkfPvQ4a1743yd1VtTbJr2yn3zlVdXRV\nHZ7k3yV526j/9yQ/XVVPr5mvrqrvXxSUtn6OH6+q1d395Ty4qrizuWaMubaqzkvyU5k9A7q4zQ5/\nP0luT3LE3C3CU/z78ef2pCQ/OfeZP57k+6rq8Kr6miQ/v6jf7Um2+/2W3X1zkr9I8tvj9//Nma3U\nPuy/TxQAQRKAvaC7/3OSX8xsY5o7M1u9+5nMVswWuyizWxw3JbkhyeLnB38iyefGrac/ndnmN8ls\nM5j3ZxYEP5zkdd39gZ1M6/ok/3vu9ZNJfjPJt2QWRP84s01tFvsfSd6X5DNJ/ibJfxifcUOSF2S2\nIcyWzG6z/Vc7uPZpSa6vqnsz23jnzJ08n/iE0e7eJNck+aYkz+ru9+2g/XZ/P939qSRvTfKZcevt\nlNtTPzg+z5VJ/tPctS9O8onMbj9+Xx4MmFv9dpJfH9f75XylH8lsxfnzmW3GdF53v3/CvABYITVx\nHwIAAAAOcFYkAQAAmESQBAAAYJJlDZJV9fiquqyqPlVVn6yqZ44H8tdX1Y3j52Fz7V9cVRur6tNV\ndepc/WlVdd0495qxkUKq6uCqetuoX11Vx831WTeucWNVrVvOzwkAAHAgWe4VyVcneU93f0NmXyL8\nySTnJrmyu0/M7KH9c5Okqk5KcmaSJ2W2CcHrxg56SfL6zDYwOHG8Thv1s5Js6e4Tkrwqsy3UM3bS\nOy/J05OcnOS8+cAKAADA7lu2IDm2F/+uJG9Mku7+v939hcy+G+zC0ezCPPi9YqcnuaS77+vuz2a2\nO9zJVXVUksd190d6tjPQRYv6bB3rsiTPGauVpyZZ392bu3tLkvV5MHwCAACwB1Yt49jHZ7bF++9X\n1VOSXJvk55Ks6e5bR5vbkqwZx2uz7Rbvt4zal8bx4vrWPjcnSXffX1V3Jzlivr6dPtt15JFH9nHH\nHTfh4wEAAOw/rr322r/r7tVLabucQXJVZt/F9bPdfXVVvTrjNtatururasW+f6Sqzk5ydpIce+yx\n2bBhw0pNBQAAYEVV1U1Lbbucz0jekuSW7r56vL8ss2B5+7hdNePnHeP8piTHzPU/etQ2jePF9W36\nVNWqJIcmuWsnY22ju8/v7oXuXli9eknBGwAA4IC3bEGyu29LcnNV/eNRek6SG5JcnmTrLqrrkrxr\nHF+e5MyxE+vxmW2q89FxG+w9VfWM8fzj8xf12TrWGUmuGs9RvjfJKVV12Nhk55RRAwAAYA8t562t\nSfKzSd5SVY9K8pkkP5lZeL20qs5KclOS5yVJd19fVZdmFjbvT3JOdz8wxnlhkguSHJLkivFKZhv5\nXFxVG5NszmzX13T35qp6WZJrRruXdvfm5fygAAAAB4qaLeCxsLDQnpEEAAAOVFV1bXcvLKXtcn+P\nJAAAAPsZQRIAAIBJBEkAAAAmESQBAACYRJAEAABgEkESAACASQRJAAAAJlm10hOApapa6RnAvs3X\nBgMADxUrkgAAAEwiSAIAADCJIAkAAMAkgiQAAACTCJIAAABMIkgCAAAwiSAJAADAJIIkAAAAkwiS\nAAAATCJIAgAAMIkgCQAAwCSCJAAAAJMIkgAAAEwiSAIAADCJIAkAAMAkgiQAAACTCJIAAABMIkgC\nAAAwiSAJAADAJIIkAAAAkwiSAAAATCJIAgAAMIkgCQAAwCSCJAAAAJMIkgAAAEwiSAIAADCJIAkA\nAMAkgiQAAACTLGuQrKrPVdV1VfXxqtowaodX1fqqunH8PGyu/YuramNVfbqqTp2rP22Ms7GqXlNV\nNeoHV9XbRv3qqjpurs+6cY0bq2rdcn5OAACAA8neWJH87u5+ancvjPfnJrmyu09McuV4n6o6KcmZ\nSZ6U5LQkr6uqg0af1yd5QZITx+u0UT8ryZbuPiHJq5K8cox1eJLzkjw9yclJzpsPrAAAAOy+lbi1\n9fQkF47jC5M8d65+SXff192fTbIxyclVdVSSx3X3R7q7k1y0qM/WsS5L8pyxWnlqkvXdvbm7tyRZ\nnwfDJwAAAHtguYNkJ3l/VV1bVWeP2pruvnUc35ZkzThem+Tmub63jNracby4vk2f7r4/yd1JjtjJ\nWAAAAOyhVcs8/nd096aq+kdJ1lfVp+ZPdndXVS/zHHZohNuzk+TYY49dqWkAAADsU5Z1RbK7N42f\ndyR5R2bPK94+blfN+HnHaL4pyTFz3Y8etU3jeHF9mz5VtSrJoUnu2slYi+d3fncvdPfC6tWrd/+D\nAgAAHECWLUhW1VdX1WO3Hic5JclfJ7k8ydZdVNcledc4vjzJmWMn1uMz21Tno+M22Huq6hnj+cfn\nL+qzdawzklw1nqN8b5JTquqwscnOKaMGAADAHlrOW1vXJHnH+KaOVUn+R3e/p6quSXJpVZ2V5KYk\nz0uS7r6+qi5NckOS+5Oc090PjLFemOSCJIckuWK8kuSNSS6uqo1JNme262u6e3NVvSzJNaPdS7t7\n8zJ+VgAAgANGzRbwWFhY6A0bNqz0NNiJ2f9JALvLX/cAwM5U1bVzX9u4Uyvx9R8AAADswwRJAAAA\nJhEkAQAAmESQBAAAYBJBEgAAgEkESQAAACYRJAEAAJhEkAQAAGASQRIAAIBJBEkAAAAmESQBAACY\nRJAEAABgEkESAACASQRJAAAAJhEkAQAAmESQBAAAYBJBEgAAgEkESQAAACYRJAEAAJhEkAQAAGAS\nQRIAAIBJBEkAAAAmESQBAACYRJAEAABgEkESAACASQRJAAAAJhEkAQAAmESQBAAAYBJBEgAAgEkE\nSQAAACYRJAEAAJhEkAQAAGASQRIAAIBJBEkAAAAmESQBAACYRJAEAABgkmUPklV1UFX9ZVW9e7w/\nvKrWV9WN4+dhc21fXFUbq+rTVXXqXP1pVXXdOPeaqqpRP7iq3jbqV1fVcXN91o1r3FhV65b7cwIA\nABwo9saK5M8l+eTc+3OTXNndJya5crxPVZ2U5MwkT0pyWpLXVdVBo8/rk7wgyYnjddqon5VkS3ef\nkORVSV45xjo8yXlJnp7k5CTnzQdWAAAAdt+yBsmqOjrJ9yd5w1z59CQXjuMLkzx3rn5Jd9/X3Z9N\nsjHJyVV1VJLHdfdHuruTXLSoz9axLkvynLFaeWqS9d29ubu3JFmfB8MnAAAAe2C5VyR/N8mvJvny\nXG1Nd986jm9LsmYcr01y81y7W0Zt7TheXN+mT3ffn+TuJEfsZCwAAAD20LIFyar6gSR3dPe1O2oz\nVhh7ueawK1V1dlVtqKoNd95550pNAwAAYJ+ynCuS357kB6vqc0kuSfLsqnpzktvH7aoZP+8Y7Tcl\nOWau/9GjtmkcL65v06eqViU5NMldOxlrG919fncvdPfC6tWrd/+TAgAAHECWLUh294u7++juPi6z\nTXSu6u4fT3J5kq27qK5L8q5xfHmSM8dOrMdntqnOR8dtsPdU1TPG84/PX9Rn61hnjGt0kvcmOaWq\nDhub7JwyagAAAOyhVStwzVckubSqzkpyU5LnJUl3X19Vlya5Icn9Sc7p7gdGnxcmuSDJIUmuGK8k\neWOSi6tqY5LNmQXWdPfmqnpZkmtGu5d29+bl/mAAAAAHgpot4LGwsNAbNmxY6WmwE7NvDwV2l7/u\nAYCdqapru3thKW33xvdIAgAAsB8RJAEAAJhEkAQAAGASQRIAAIBJBEkAAAAmESQBAACYRJAEAABg\nEkESAACASQRJAAAAJhEkAQAAmESQBAAAYBJBEgAAgEkESQAAACYRJAEAAJhEkAQAAGASQRIAAIBJ\nBEkAAAAmESQBAACYRJAEAABgEkESAACASQRJAAAAJhEkAQAAmESQBAAAYBJBEgAAgEkESQAAACYR\nJAEAAJhEkAQAAGCSJQXJqvr2pdQAAADY/y11RfK/LLEGAADAfm7Vzk5W1TOTfFuS1VX1i3OnHpfk\noOWcGAAAAA9POw2SSR6V5DGj3WPn6vckOWO5JgUAAMDD106DZHd/MMkHq+qC7r5pL80JAACAh7Fd\nrUhudXBVnZ/kuPk+3f3s5ZgUAAAAD19LDZJ/kOS/JnlDkgeWbzoAAAA83C01SN7f3a9f1pkAAACw\nT1jq13/8UVW9sKqOqqrDt76WdWYAAAA8LC11RXLd+Pkrc7VO8nUP7XQAAAB4uFvSimR3H7+d105D\nZFU9uqo+WlWfqKrrq+o3R/3wqlpfVTeOn4fN9XlxVW2sqk9X1alz9adV1XXj3Guqqkb94Kp626hf\nXVXHzfVZN65xY1WtCwAAAA+JJa1IVtXzt1fv7ot20u2+JM/u7nur6pFJ/ryqrkjyz5Nc2d2vqKpz\nk5yb5EVVdVKSM5M8KckTkry/qp7Y3Q8keX2SFyS5OsmfJDktyRVJzkqypbtPqKozk7wyyQ+P227P\nS7KQ2crptVV1eXdvWcrnBQAAYMeW+ozkt869vjPJS5L84M469My94+0jx6uTnJ7kwlG/MMlzx/Hp\nSS7p7vu6+7NJNiY5uaqOSvK47v5Id3eSixb12TrWZUmeM1YrT02yvrs3j/C4PrPwCQAAwB5a0opk\nd//s/PuqenySS3bVr6oOSnJtkhOSvLa7r66qNd1962hyW5I143htko/Mdb9l1L40jhfXt/a5eczx\n/qq6O8kR8/Xt9Jmf39lJzk6SY489dlcfBwAAgCx9RXKxLyY5fleNuvuB7n5qkqMzW1188qLzndkq\n5Yro7vO7e6G7F1avXr1S0wAAANinLPUZyT/Kg4HvoCTfmOTSpV6ku79QVR/I7PbS26vqqO6+ddy2\nesdotinJMXPdjh61TeN4cX2+zy1VtSrJoUnuGvVnLerzp0udLwAAADu21BXJ/5TkP4/Xy5N8V3ef\nu7MOVbV63AKbqjokyT9N8qkkl+fBrxNZl+Rd4/jyJGeOnViPT3Jiko+O22DvqapnjOcfn7+oz9ax\nzkhy1VjlfG+SU6rqsLEr7CmjBgAAwB5a6jOSH6yqNZlttpMkNy6h21FJLhzPST4iyaXd/e6q+nCS\nS6vqrCQ3JXneuMb1VXVpkhuS3J/knLFja5K8MMkFSQ7JbLfWK0b9jUkurqqNSTZntutruntzVb0s\nyTWj3Uu7e/NSPisAAAA7V7MFvF00qnpekv+Y2e2hldnOrb/S3Zct6+z2ooWFhd6wYcNKT4OdmH17\nKLC7lvDXPQBwAKuqa7t7YSltl7QimeTfJfnW7r5jXGB1kvdn9pUbAAAAHECW+ozkI7aGyOGuCX0B\nAADYjyx1RfI9VfXeJG8d7384yZ8sz5QAAAB4ONtpkKyqE5Ks6e5fqap/nuQ7xqkPJ3nLck8OAACA\nh59drUj+bpIXJ0l3vz3J25Okqr5pnPtnyzo7AAAAHnZ29Zzjmu6+bnFx1I5blhkBAADwsLarIPn4\nnZw75KGcCAAAAPuGXQXJDVX1gsXFqvqpJNcuz5QAAAB4ONvVM5I/n+QdVfVjeTA4LiR5VJIfWs6J\nAQAA8PC00yDZ3bcn+baq+u4kTx7lP+7uq5Z9ZgAAADwsLel7JLv7A0k+sMxzAQAAYB+wq2ckAQAA\nYBuCJAAAAJMIkgAAAEwiSAIAADCJIAkAAMAkgiQAAACTCJIAAABMIkgCAAAwiSAJAADAJIIkAAAA\nkwiSAAAATCJIAgAAMIkgCQAAwCSCJAAAAJMIkgAAAEwiSAIAADCJIAkAAMAkgiQAAACTCJIAAABM\nIkgCAAAwiSAJAADAJIIkAAAAkwiSAAAATCJIAgAAMIkgCQAAwCTLFiSr6piq+kBV3VBV11fVz436\n4VW1vqpuHD8Pm+vz4qraWFWfrqpT5+pPq6rrxrnXVFWN+sFV9bZRv7qqjpvrs25c48aqWrdcnxMA\nAOBAs5wrkvcn+aXuPinJM5KcU1UnJTk3yZXdfWKSK8f7jHNnJnlSktOSvK6qDhpjvT7JC5KcOF6n\njfpZSbZ09wlJXpXklWOsw5Ocl+TpSU5Oct58YAUAAGD3LVuQ7O5bu/tj4/jvk3wyydokpye5cDS7\nMMlzx/HpSS7p7vu6+7NJNiY5uaqOSvK47v5Id3eSixb12TrWZUmeM1YrT02yvrs3d/eWJOvzYPgE\nAABgD+yVZyTHLaf/JMnVSdZ0963j1G1J1ozjtUlunut2y6itHceL69v06e77k9yd5IidjLV4XmdX\n1Yaq2nDnnXfu5qcDAAA4sCx7kKyqxyT5wyQ/3933zJ8bK4y93HPYke4+v7sXunth9erVKzUNAACA\nfcqyBsmqemRmIfIt3f32Ub593K6a8fOOUd+U5Ji57keP2qZxvLi+TZ+qWpXk0CR37WQsAAAA9tBy\n7tpaSd6Y5JPd/Ttzpy5PsnUX1XVJ3jVXP3PsxHp8ZpvqfHTcBntPVT1jjPn8RX22jnVGkqvGKud7\nk5xSVYeNTXZOGTUAAAD20KplHPvbk/xEkuuq6uOj9mtJXpHk0qo6K8lNSZ6XJN19fVVdmuSGzHZ8\nPae7Hxj9XpjkgiSHJLlivJJZUL24qjYm2ZzZrq/p7s1V9bIk14x2L+3uzcv1QQEAAA4kNVvAY2Fh\noTds2LDS02AnZt8eCuwuf90DADtTVdd298JS2u6VXVsBAADYfwiSAAAATCJIAgAAMIkgCQAAwCSC\nJAAAAJMIkgAAAEwiSAIAADCJIAkAAMAkgiQAAACTCJIAAABMIkgCAAAwiSAJAADAJIIkAAAAkwiS\nAAAATCJIAgAAMIkgCQAAwCSCJAAAAJMIkgAAAEwiSAIAADCJIAkAAMAkgiQAAACTCJIAAABMIkgC\nAAAwiSAJAADAJIIkAAAAkwiSAAAATCJIAgAAMIkgCQAAwCSCJAAAAJMIkgAAAEwiSAIAADCJIAkA\nAMAkgiQAAACTCJIAAABMIkgCAAAwiSAJAADAJMsWJKvqTVV1R1X99Vzt8KpaX1U3jp+HzZ17cVVt\nrKpPV9Wpc/WnVdV149xrqqpG/eCqetuoX11Vx831WTeucWNVrVuuzwgAAHAgWs4VyQuSnLaodm6S\nK7v7xCRXjvepqpOSnJnkSaPP66rqoNHn9UlekOTE8do65llJtnT3CUleleSVY6zDk5yX5OlJTk5y\n3nxgBQAAYM8sW5Ds7j9LsnlR+fQkF47jC5M8d65+SXff192fTbIxyclVdVSSx3X3R7q7k1y0qM/W\nsS5L8pyxWnlqkvXdvbm7tyRZn68MtAAAAOymvf2M5JruvnUc35ZkzThem+TmuXa3jNracby4vk2f\n7r4/yd1JjtjJWF+hqs6uqg1VteHOO+/c3c8EAABwQFmxzXbGCmOv1PXHHM7v7oXuXli9evVKTgUA\nAGCfsbeD5O3jdtWMn3eM+qYkx8y1O3rUNo3jxfVt+lTVqiSHJrlrJ2MBAADwENjbQfLyJFt3UV2X\n5F1z9TPHTqzHZ7apzkfHbbD3VNUzxvOPz1/UZ+tYZyS5aqxyvjfJKVV12Nhk55RRAwAA4CGwarkG\nrqq3JnlWkiOr6pbMdlJ9RZJLq+qsJDcleV6SdPf1VXVpkhuS3J/knO5+YAz1wsx2gD0kyRXjlSRv\nTHJxVW3MbFOfM8dYm6vqZUmuGe1e2t2LN/0BAABgN9VsEY+FhYXesGHDSk+DnZh9gyiwu/x1DwDs\nTFVd290LS2m7YpvtAAAAsG8SJAEAAJhEkAQAAGASQRIAAIBJBEkAAAAmESQBAACYRJAEAABgEkES\nAACASQRJAAAAJhEkAQAAmESQBAAAYBJBEgAAgEkESQAAACYRJAEAAJhEkAQAAGASQRIAAIBJBEkA\nAAAmESQBAACYRJAEAABgEkESAACASQRJAAAAJhEkAQAAmESQBAAAYBJBEgAAgEkESQAAACYRJAEA\nAJhEkAQAAGASQRIAAIBJBEkAAAAmESQBAACYZNVKTwAAYF9RtdIzgH1b90rPgIeKFUkAAAAmESQB\nAACYRJAEAABgEkESAACASQRJAAAAJtmvg2RVnVZVn66qjVV17krPBwAAYH+w3wbJqjooyWuTfG+S\nk5L8SFWdtLKzAgAA2Pftt0EyyclJNnb3Z7r7/ya5JMnpKzwnAACAfd6qlZ7AMlqb5Oa597ckefp8\ng6o6O8nZ4+29VfXpvTQ32F8dmeTvVnoSbJ8vUgcOAP4depjzb9HD3tcuteH+HCR3qbvPT3L+Ss8D\n9hdVtaG7F1Z6HgAcmPw7BHvP/nxr66Ykx8y9P3rUAAAA2AP7c5C8JsmJVXV8VT0qyZlJLl/hOQEA\nAOzz9ttbW7v7/qr6mSTvTXJQkjd19/UrPC3Y37lVHICV5N8h2Euqu1d6DgAAAOxD9udbWwEAAFgG\ngiQAAACTCJIAAABMst9utgMsr6r6hiSnJ1k7SpuSXN7dn1y5WQEAsDdYkQQmq6oXJbkkSSX56HhV\nkrdW1bkrOTcAqKqfXOk5wP7Orq3AZFX1P5M8qbu/tKj+qCTXd/eJKzMzAEiq6m+7+9iVngfsz9za\nCuyOLyd5QpKbFtWPGucAYFlV1V/t6FSSNXtzLnAgEiSB3fHzSa6sqhuT3DxqxyY5IcnPrNisADiQ\nrElyapIti+qV5C/2/nTgwCJIApN193uq6olJTs62m+1c090PrNzMADiAvDvJY7r744tPVNWf7v3p\nwIHFM5IAAABMYtdWAAAAJhEkAQAAmESQBIBFquprquqSqvqbqrq2qv6kqp5YVcdV1V8v0zVfUlW/\nPKH9vcs5PgDsjM12AGBOVVWSdyS5sLvPHLWnZLZD5M076wsABworkgCwre9O8qXu/q9bC939ie7+\n0HyjsTr5oar62Hh926gfVVV/VlUfr6q/rqrvrKqDquqC8f66qvqFpU6mqt45VkWvr6qzF5171ahf\nWVWrR+3rq+o9o8+HquobtjPmv62qG6rqr6rqkom/HwCwIgkAizw5ybVLaHdHkn/a3f+nqk5M8tYk\nC0l+NMl7u/u3quqgJF+V5KlJ1nb3k5Okqh4/YT7/urs3V9UhSa6pqj/s7ruSfHWSDd39C1X1G0nO\ny+x7XM9P8tPdfWNVPT3J65I8e9GY5yY5vrvvmzgXAEgiSALA7npkkt+rqqcmeSDJE0f9miRvqqpH\nJnlnd39mEjSGAAAB4UlEQVS8qj6T5Ouq6r8k+eMk75twnX9bVT80jo9JcmKSu5J8OcnbRv3NSd5e\nVY9J8m1J/mB2h26S5ODtjPlXSd5SVe9M8s4JcwGAJG5tBYDFrk/ytCW0+4Uktyd5SmYrkY9Kku7+\nsyTflWRTkguq6vndvWW0+9MkP53kDUuZSFU9K8n3JHlmdz8lyV8mefQOmndm/65/obufOvf6xu20\n/f4kr03yLZmtcvqPZQAmESQBYFtXJTl4/nnEqvrmqvrORe0OTXJrd385yU8kOWi0/dokt3f3f88s\nMH5LVR2Z5BHd/YdJfj2zALcUhybZ0t3/azzr+Iy5c49IcsY4/tEkf97d9yT5bFX9yzGXGhsF/YOq\nekSSY7r7A0leNK7xmCXOBwCSCJIAsI3u7iQ/lOR7xtd/XJ/kt5Pctqjp65Ksq6pPJPmGJF8c9Wcl\n+URV/WWSH07y6iRrk/xpVX08s9tQX7yDy/96Vd2y9ZXkPUlWVdUnk7wiyUfm2n4xycnj60ieneSl\no/5jSc4a87o+yemLrnFQkjdX1XWZrXC+pru/sJTfDQBsVbN/LwEAAGBprEgCAAAwiSAJAADAJIIk\nAAAAkwiSAAAATCJIAgAAMIkgCQAAwCSCJAAAAJMIkgAAAEzy/wAXItjOxgHlZAAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109198518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the proportion of the target variables\n",
    "fig = plt.figure(figsize = (15,5))\n",
    "\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "print(df[\"target\"].value_counts())\n",
    "df[\"target\"].value_counts().plot(kind='bar', color='blue')\n",
    "plt.xlabel(\"Class Labels\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class Labels Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe the above, the proportion of class labels (0 & 1) are very imbalanced. SMOTE technique might be one of our approach to achieve a better result. The SMOTE process includes Over-Sampling the Minority Class and Under-Sampling the Majority Class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set y as the target variable Table\n",
    "Y = df.target\n",
    "#Set X_norm as the Normalized predictor variables Table\n",
    "X_norm = df.iloc[:,1:]\n",
    "#Set X as the predictor variables Table\n",
    "X = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/KevQuant/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Split the train set, test set, train class, test class\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, \n",
    "                                                 #Predictor Variables\n",
    "                                                 Y, \n",
    "                                                 #Class labels\n",
    "                                                 stratify=y, \n",
    "                                                 #data is split in a stratified fashion, using this as the class labels\n",
    "                                                 test_size=0.34,\n",
    "                                                 #Test size is set as 34% of entire set\n",
    "                                                 random_state=28,\n",
    "                                                 # Set the randon state for spliting data  in same order\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimenision of Training Sample is  (392839, 57)\n",
      "The dimenision of Training Target Classes is  (392839,)\n",
      "The dimenision of Testing Sample is  (202373, 57)\n",
      "The dimenision of Testing Target Classes is  (202373,)\n"
     ]
    }
   ],
   "source": [
    "#Double check the dimenision of the Data Samples\n",
    "print(\"The dimenision of Training Sample is \",x_train.shape)\n",
    "print(\"The dimenision of Training Target Classes is \",y_train.shape)\n",
    "print(\"The dimenision of Testing Sample is \",x_test.shape)\n",
    "print(\"The dimenision of Testing Target Classes is \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Desision Tree, Naive Bayes , K-Nearest Neighors\n",
    "from sklearn import neighbors, tree, naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set up Decision Tree classifier with ALL default setting\n",
    "treeclf = tree.DecisionTreeClassifier()\n",
    "#Plug in the train dataset with target class\n",
    "treeclf = treeclf.fit(x_train, y_train)\n",
    "treeclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202373,)\n"
     ]
    }
   ],
   "source": [
    "#Classify the Target Class\n",
    "y_pre = treeclf.predict(x_test)\n",
    "print (y_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.95      0.96    194997\n",
      "          1       0.04      0.06      0.05      7376\n",
      "\n",
      "avg / total       0.93      0.92      0.92    202373\n",
      "\n",
      "---Confusion Matrix---\n",
      "[[185400   9597]\n",
      " [  6926    450]]\n",
      "\n",
      "Specificity: Decision Tree Classifier: 95.078 percent\n",
      "Sensitivity: Decision Tree Classifier: 6.101 percent\n",
      "\n",
      "Accuracy of Training: Decision Tree Classifier: 100.000 percent\n",
      "Accuracy of Training: Decision Tree Classifier: 91.835 percent\n"
     ]
    }
   ],
   "source": [
    "#Generate the Classification Report\n",
    "#Generate the precision, recall, F1 score for each class\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pre))\n",
    "#Generate confustion matrix \n",
    "#Columns represent the Actual Values 1 through 3 from top to bottom\n",
    "#Rows represent the Predicted Values 1 through 3 from left to right\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tree_cm = confusion_matrix(y_test, y_pre, labels=[0,1])\n",
    "print(\"---Confusion Matrix---\")\n",
    "print (tree_cm)\n",
    "print()\n",
    "tree_specficity = tree_cm[0,0] / (tree_cm[0,0]+tree_cm[0,1])\n",
    "tree_sensitivity = tree_cm[1,1] / (tree_cm[1,0]+tree_cm[1,1])\n",
    "print(\"Specificity: Decision Tree Classifier: %0.3f percent\" % (tree_specficity*100))\n",
    "print(\"Sensitivity: Decision Tree Classifier: %0.3f percent\" %(tree_sensitivity*100))\n",
    "print()\n",
    "#The average Accuracy score across the train instances\n",
    "print (\"Accuracy of Training: Decision Tree Classifier: %0.3f percent\" %(treeclf.score(x_train, y_train)*100))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy of Training: Decision Tree Classifier: %0.3f percent\" %(accuracy_score(y_test, y_pre)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##By GridSearch and Cross-Validation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, naive_bayes, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 57)\n",
      "(595212,)\n"
     ]
    }
   ],
   "source": [
    "Y = df.target\n",
    "X= df.iloc[:,1:]\n",
    "X.shape\n",
    "\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,   2.,   5., ...,   0.,   0.,   1.],\n",
       "       [  1.,   1.,   7., ...,   0.,   1.,   0.],\n",
       "       [  5.,   4.,   9., ...,   0.,   1.,   0.],\n",
       "       ..., \n",
       "       [  1.,   1.,  10., ...,   0.,   0.,   0.],\n",
       "       [  5.,   2.,   3., ...,   1.,   0.,   0.],\n",
       "       [  0.,   1.,   8., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning D.T. parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 25}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.500 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 5}\n",
      "0.504 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 15}\n",
      "0.506 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 25}\n",
      "0.505 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 35}\n",
      "0.506 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 45}\n",
      "0.505 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 55}\n",
      "0.506 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 65}\n",
      "0.500 (+/-0.000) for {'criterion': 'gini', 'max_depth': 5}\n",
      "0.503 (+/-0.000) for {'criterion': 'gini', 'max_depth': 15}\n",
      "0.507 (+/-0.000) for {'criterion': 'gini', 'max_depth': 25}\n",
      "0.507 (+/-0.002) for {'criterion': 'gini', 'max_depth': 35}\n",
      "0.505 (+/-0.001) for {'criterion': 'gini', 'max_depth': 45}\n",
      "0.507 (+/-0.002) for {'criterion': 'gini', 'max_depth': 55}\n",
      "0.506 (+/-0.003) for {'criterion': 'gini', 'max_depth': 65}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97    194997\n",
      "          1       0.05      0.04      0.04      7376\n",
      "\n",
      "avg / total       0.93      0.93      0.93    202373\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Split the train set, test set, train class, test class\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, \n",
    "                                                 #Predictor Variables\n",
    "                                                 Y, \n",
    "                                                 #Class labels\n",
    "                                                 stratify=Y, \n",
    "                                                 #data is split in a stratified fashion, using this as the class labels\n",
    "                                                 test_size=0.34,\n",
    "                                                 #Test size is set as 34% of entire set\n",
    "                                                 random_state=28,\n",
    "                                                 # Set the randon state for spliting data  in same order\n",
    "                                                )\n",
    "\n",
    "#Pre-set parameters for the classifier\n",
    "max_depth_lst=list(np.arange(5,70,10))\n",
    "tuned_parameters = [{\"criterion\" : [\"entropy\"],\n",
    "                     \"max_depth\": max_depth_lst}, \n",
    "                    {\"criterion\" : [\"gini\"],\n",
    "                     \"max_depth\": max_depth_lst}]\n",
    "\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning D.T. parameters for %s\" % score)\n",
    "    print()\n",
    "    #Find the best parameters value to the classifier by cross-validation method\n",
    "    clf = GridSearchCV(tree.DecisionTreeClassifier(), tuned_parameters, cv=2, scoring='%s_macro' % score)\n",
    " \n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score of Training dataset 0.988175817574\n",
      "The Score of Testing dataset 0.933355734214\n",
      " \n",
      "[[378406    115]\n",
      " [  4530   9788]]\n",
      " \n",
      "Decision Tree Classifier: Specificity on Training Raw Data is  0.999696185945\n",
      "Decision Tree Classifier: Sensivtivity on Training Raw Data is  0.683615030032\n",
      " \n",
      "[[188570   6427]\n",
      " [  7060    316]]\n",
      " \n",
      "Decision Tree Classifier: Specificity on Testing Raw Data is  0.967040518572\n",
      "Decision Tree Classifier: Sensivtivity on Testing Raw Data is  0.04284164859\n"
     ]
    }
   ],
   "source": [
    "#Split the train set, test set, train class, test class\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, \n",
    "                                                 #Predictor Variables\n",
    "                                                 Y, \n",
    "                                                 #Class labels\n",
    "                                                 stratify=Y, \n",
    "                                                 #data is split in a stratified fashion, using this as the class labels\n",
    "                                                 test_size=0.34,\n",
    "                                                 #Test size is set as 34% of entire set\n",
    "                                                 random_state=28,\n",
    "                                                 # Set the randon state for spliting data  in same order\n",
    "                                                )\n",
    "clf = tree.DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                  random_state=28,\n",
    "                                  max_depth=25 )\n",
    "                                  #min_samples_split= 4, \n",
    "                                  #min_samples_leaf= 1)\n",
    "clf.fit(x_train,y_train)\n",
    "print(\"The Score of Training dataset\",clf.score(x_train, y_train))\n",
    "print(\"The Score of Testing dataset\",clf.score(x_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "pred_train = clf.predict(x_train)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train, pred_train) #Generate the confusion matrix\n",
    "print(cm)\n",
    "print(' ')\n",
    "\n",
    "#Class 1 means True Customers\n",
    "specificity1_train = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "sensitivity1_train = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Decision Tree Classifier: Specificity on Training Raw Data is \", specificity1_train)\n",
    "print(\"Decision Tree Classifier: Sensivtivity on Training Raw Data is \", sensitivity1_train)\n",
    "print(' ')\n",
    "\n",
    "#Use the SAME classifier to predict on the provided Testing Set\n",
    "pred_test = clf.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, pred_test) #Generate the confusion matrix\n",
    "print(cm)\n",
    "print(' ')\n",
    "\n",
    "#Class 1 means True Customers\n",
    "specificity1_test = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "sensitivity1_test = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Decision Tree Classifier: Specificity on Testing Raw Data is \", specificity1_test)\n",
    "print(\"Decision Tree Classifier: Sensivtivity on Testing Raw Data is \", sensitivity1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning N.B. parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'binarize': 0.89000009999999996}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.501 (+/-0.000) for {'binarize': 9.9999999999999995e-08}\n",
      "0.501 (+/-0.000) for {'binarize': 0.0100001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.0200001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.030000099999999998}\n",
      "0.501 (+/-0.000) for {'binarize': 0.040000100000000004}\n",
      "0.501 (+/-0.000) for {'binarize': 0.050000100000000006}\n",
      "0.501 (+/-0.000) for {'binarize': 0.060000100000000001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.07000010000000001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.080000100000000005}\n",
      "0.501 (+/-0.000) for {'binarize': 0.0900001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.10000010000000001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.1100001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.1200001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.13000010000000001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.14000010000000002}\n",
      "0.501 (+/-0.000) for {'binarize': 0.1500001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.16000010000000001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.17000010000000002}\n",
      "0.501 (+/-0.000) for {'binarize': 0.1800001}\n",
      "0.501 (+/-0.000) for {'binarize': 0.19000010000000001}\n",
      "0.501 (+/-0.001) for {'binarize': 0.20000010000000001}\n",
      "0.501 (+/-0.001) for {'binarize': 0.2100001}\n",
      "0.501 (+/-0.001) for {'binarize': 0.2200001}\n",
      "0.501 (+/-0.001) for {'binarize': 0.23000010000000001}\n",
      "0.501 (+/-0.001) for {'binarize': 0.24000009999999999}\n",
      "0.501 (+/-0.001) for {'binarize': 0.2500001}\n",
      "0.501 (+/-0.001) for {'binarize': 0.26000010000000001}\n",
      "0.501 (+/-0.001) for {'binarize': 0.27000010000000002}\n",
      "0.501 (+/-0.001) for {'binarize': 0.28000010000000003}\n",
      "0.501 (+/-0.001) for {'binarize': 0.29000009999999998}\n",
      "0.501 (+/-0.001) for {'binarize': 0.30000009999999999}\n",
      "0.501 (+/-0.001) for {'binarize': 0.3100001}\n",
      "0.501 (+/-0.001) for {'binarize': 0.32000010000000001}\n",
      "0.501 (+/-0.001) for {'binarize': 0.33000010000000002}\n",
      "0.501 (+/-0.001) for {'binarize': 0.34000010000000003}\n",
      "0.501 (+/-0.001) for {'binarize': 0.35000010000000004}\n",
      "0.501 (+/-0.001) for {'binarize': 0.36000009999999999}\n",
      "0.501 (+/-0.001) for {'binarize': 0.3700001}\n",
      "0.501 (+/-0.001) for {'binarize': 0.38000010000000001}\n",
      "0.501 (+/-0.001) for {'binarize': 0.39000010000000002}\n",
      "0.502 (+/-0.001) for {'binarize': 0.40000010000000003}\n",
      "0.502 (+/-0.001) for {'binarize': 0.41000010000000003}\n",
      "0.502 (+/-0.001) for {'binarize': 0.42000009999999999}\n",
      "0.502 (+/-0.001) for {'binarize': 0.4300001}\n",
      "0.502 (+/-0.001) for {'binarize': 0.44000010000000001}\n",
      "0.502 (+/-0.001) for {'binarize': 0.45000010000000001}\n",
      "0.502 (+/-0.001) for {'binarize': 0.46000010000000002}\n",
      "0.502 (+/-0.001) for {'binarize': 0.47000010000000003}\n",
      "0.502 (+/-0.001) for {'binarize': 0.48000009999999999}\n",
      "0.502 (+/-0.001) for {'binarize': 0.49000009999999999}\n",
      "0.503 (+/-0.001) for {'binarize': 0.50000009999999995}\n",
      "0.502 (+/-0.001) for {'binarize': 0.51000009999999996}\n",
      "0.502 (+/-0.001) for {'binarize': 0.52000009999999997}\n",
      "0.503 (+/-0.001) for {'binarize': 0.53000009999999997}\n",
      "0.503 (+/-0.001) for {'binarize': 0.54000009999999998}\n",
      "0.503 (+/-0.000) for {'binarize': 0.55000009999999999}\n",
      "0.502 (+/-0.000) for {'binarize': 0.5600001}\n",
      "0.502 (+/-0.001) for {'binarize': 0.57000010000000001}\n",
      "0.502 (+/-0.001) for {'binarize': 0.58000009999999991}\n",
      "0.502 (+/-0.001) for {'binarize': 0.59000009999999992}\n",
      "0.502 (+/-0.001) for {'binarize': 0.60000009999999993}\n",
      "0.502 (+/-0.001) for {'binarize': 0.61000009999999993}\n",
      "0.502 (+/-0.001) for {'binarize': 0.62000009999999994}\n",
      "0.502 (+/-0.001) for {'binarize': 0.63000009999999995}\n",
      "0.502 (+/-0.001) for {'binarize': 0.64000009999999996}\n",
      "0.502 (+/-0.001) for {'binarize': 0.65000009999999997}\n",
      "0.502 (+/-0.001) for {'binarize': 0.66000009999999998}\n",
      "0.502 (+/-0.001) for {'binarize': 0.67000009999999999}\n",
      "0.502 (+/-0.001) for {'binarize': 0.6800001}\n",
      "0.502 (+/-0.001) for {'binarize': 0.69000010000000001}\n",
      "0.502 (+/-0.000) for {'binarize': 0.70000010000000001}\n",
      "0.502 (+/-0.000) for {'binarize': 0.71000009999999991}\n",
      "0.502 (+/-0.000) for {'binarize': 0.72000009999999992}\n",
      "0.502 (+/-0.000) for {'binarize': 0.73000009999999993}\n",
      "0.502 (+/-0.000) for {'binarize': 0.74000009999999994}\n",
      "0.502 (+/-0.000) for {'binarize': 0.75000009999999995}\n",
      "0.502 (+/-0.000) for {'binarize': 0.76000009999999996}\n",
      "0.502 (+/-0.000) for {'binarize': 0.77000009999999997}\n",
      "0.502 (+/-0.000) for {'binarize': 0.78000009999999997}\n",
      "0.502 (+/-0.000) for {'binarize': 0.79000009999999998}\n",
      "0.503 (+/-0.000) for {'binarize': 0.80000009999999999}\n",
      "0.503 (+/-0.000) for {'binarize': 0.8100001}\n",
      "0.503 (+/-0.000) for {'binarize': 0.82000010000000001}\n",
      "0.503 (+/-0.001) for {'binarize': 0.83000010000000002}\n",
      "0.503 (+/-0.001) for {'binarize': 0.84000009999999992}\n",
      "0.503 (+/-0.001) for {'binarize': 0.85000009999999993}\n",
      "0.503 (+/-0.001) for {'binarize': 0.86000009999999993}\n",
      "0.503 (+/-0.001) for {'binarize': 0.87000009999999994}\n",
      "0.503 (+/-0.001) for {'binarize': 0.88000009999999995}\n",
      "0.503 (+/-0.001) for {'binarize': 0.89000009999999996}\n",
      "0.503 (+/-0.001) for {'binarize': 0.90000009999999997}\n",
      "0.503 (+/-0.001) for {'binarize': 0.91000009999999998}\n",
      "0.503 (+/-0.001) for {'binarize': 0.92000009999999999}\n",
      "0.503 (+/-0.001) for {'binarize': 0.9300001}\n",
      "0.503 (+/-0.001) for {'binarize': 0.94000010000000001}\n",
      "0.503 (+/-0.001) for {'binarize': 0.95000010000000001}\n",
      "0.503 (+/-0.001) for {'binarize': 0.96000009999999991}\n",
      "0.503 (+/-0.000) for {'binarize': 0.97000009999999992}\n",
      "0.503 (+/-0.000) for {'binarize': 0.98000009999999993}\n",
      "0.503 (+/-0.001) for {'binarize': 0.99000009999999994}\n",
      "0.501 (+/-0.000) for {'alpha': 0.10000000000000001}\n",
      "0.501 (+/-0.000) for {'alpha': 0.1090909090909091}\n",
      "0.501 (+/-0.000) for {'alpha': 0.11818181818181819}\n",
      "0.501 (+/-0.000) for {'alpha': 0.12727272727272729}\n",
      "0.501 (+/-0.000) for {'alpha': 0.13636363636363635}\n",
      "0.501 (+/-0.000) for {'alpha': 0.14545454545454545}\n",
      "0.501 (+/-0.000) for {'alpha': 0.15454545454545454}\n",
      "0.501 (+/-0.000) for {'alpha': 0.16363636363636364}\n",
      "0.501 (+/-0.000) for {'alpha': 0.17272727272727273}\n",
      "0.501 (+/-0.000) for {'alpha': 0.18181818181818182}\n",
      "0.501 (+/-0.000) for {'alpha': 0.19090909090909092}\n",
      "0.501 (+/-0.000) for {'alpha': 0.20000000000000001}\n",
      "0.501 (+/-0.000) for {'alpha': 0.20909090909090911}\n",
      "0.501 (+/-0.000) for {'alpha': 0.2181818181818182}\n",
      "0.501 (+/-0.000) for {'alpha': 0.22727272727272727}\n",
      "0.501 (+/-0.000) for {'alpha': 0.23636363636363636}\n",
      "0.501 (+/-0.000) for {'alpha': 0.24545454545454545}\n",
      "0.501 (+/-0.000) for {'alpha': 0.25454545454545452}\n",
      "0.501 (+/-0.000) for {'alpha': 0.26363636363636367}\n",
      "0.501 (+/-0.000) for {'alpha': 0.27272727272727271}\n",
      "0.501 (+/-0.000) for {'alpha': 0.28181818181818186}\n",
      "0.501 (+/-0.000) for {'alpha': 0.29090909090909089}\n",
      "0.501 (+/-0.000) for {'alpha': 0.29999999999999999}\n",
      "0.501 (+/-0.000) for {'alpha': 0.30909090909090908}\n",
      "0.501 (+/-0.000) for {'alpha': 0.31818181818181818}\n",
      "0.501 (+/-0.000) for {'alpha': 0.32727272727272727}\n",
      "0.501 (+/-0.000) for {'alpha': 0.33636363636363636}\n",
      "0.501 (+/-0.000) for {'alpha': 0.34545454545454546}\n",
      "0.501 (+/-0.000) for {'alpha': 0.3545454545454545}\n",
      "0.501 (+/-0.000) for {'alpha': 0.36363636363636365}\n",
      "0.501 (+/-0.000) for {'alpha': 0.37272727272727268}\n",
      "0.501 (+/-0.000) for {'alpha': 0.38181818181818183}\n",
      "0.501 (+/-0.000) for {'alpha': 0.39090909090909087}\n",
      "0.501 (+/-0.000) for {'alpha': 0.40000000000000002}\n",
      "0.501 (+/-0.000) for {'alpha': 0.40909090909090906}\n",
      "0.501 (+/-0.000) for {'alpha': 0.41818181818181821}\n",
      "0.501 (+/-0.000) for {'alpha': 0.42727272727272725}\n",
      "0.501 (+/-0.000) for {'alpha': 0.4363636363636364}\n",
      "0.501 (+/-0.000) for {'alpha': 0.44545454545454544}\n",
      "0.501 (+/-0.000) for {'alpha': 0.45454545454545459}\n",
      "0.501 (+/-0.000) for {'alpha': 0.46363636363636362}\n",
      "0.501 (+/-0.000) for {'alpha': 0.47272727272727266}\n",
      "0.501 (+/-0.000) for {'alpha': 0.48181818181818181}\n",
      "0.501 (+/-0.000) for {'alpha': 0.49090909090909085}\n",
      "0.501 (+/-0.000) for {'alpha': 0.5}\n",
      "0.501 (+/-0.000) for {'alpha': 0.50909090909090904}\n",
      "0.501 (+/-0.000) for {'alpha': 0.51818181818181819}\n",
      "0.501 (+/-0.000) for {'alpha': 0.52727272727272723}\n",
      "0.501 (+/-0.000) for {'alpha': 0.53636363636363638}\n",
      "0.501 (+/-0.000) for {'alpha': 0.54545454545454541}\n",
      "0.501 (+/-0.000) for {'alpha': 0.55454545454545456}\n",
      "0.501 (+/-0.000) for {'alpha': 0.5636363636363636}\n",
      "0.501 (+/-0.000) for {'alpha': 0.57272727272727275}\n",
      "0.501 (+/-0.000) for {'alpha': 0.58181818181818179}\n",
      "0.501 (+/-0.000) for {'alpha': 0.59090909090909094}\n",
      "0.501 (+/-0.000) for {'alpha': 0.59999999999999998}\n",
      "0.501 (+/-0.000) for {'alpha': 0.60909090909090902}\n",
      "0.501 (+/-0.000) for {'alpha': 0.61818181818181817}\n",
      "0.501 (+/-0.000) for {'alpha': 0.6272727272727272}\n",
      "0.501 (+/-0.000) for {'alpha': 0.63636363636363635}\n",
      "0.501 (+/-0.000) for {'alpha': 0.64545454545454539}\n",
      "0.501 (+/-0.000) for {'alpha': 0.65454545454545454}\n",
      "0.501 (+/-0.000) for {'alpha': 0.66363636363636358}\n",
      "0.501 (+/-0.000) for {'alpha': 0.67272727272727273}\n",
      "0.501 (+/-0.000) for {'alpha': 0.68181818181818177}\n",
      "0.501 (+/-0.000) for {'alpha': 0.69090909090909081}\n",
      "0.501 (+/-0.000) for {'alpha': 0.69999999999999996}\n",
      "0.501 (+/-0.000) for {'alpha': 0.70909090909090899}\n",
      "0.501 (+/-0.000) for {'alpha': 0.71818181818181814}\n",
      "0.501 (+/-0.000) for {'alpha': 0.72727272727272718}\n",
      "0.501 (+/-0.000) for {'alpha': 0.73636363636363633}\n",
      "0.501 (+/-0.000) for {'alpha': 0.74545454545454537}\n",
      "0.501 (+/-0.000) for {'alpha': 0.75454545454545452}\n",
      "0.501 (+/-0.000) for {'alpha': 0.76363636363636356}\n",
      "0.501 (+/-0.000) for {'alpha': 0.77272727272727271}\n",
      "0.501 (+/-0.000) for {'alpha': 0.78181818181818175}\n",
      "0.501 (+/-0.000) for {'alpha': 0.79090909090909089}\n",
      "0.501 (+/-0.000) for {'alpha': 0.79999999999999993}\n",
      "0.501 (+/-0.000) for {'alpha': 0.80909090909090908}\n",
      "0.501 (+/-0.000) for {'alpha': 0.81818181818181812}\n",
      "0.501 (+/-0.000) for {'alpha': 0.82727272727272727}\n",
      "0.501 (+/-0.000) for {'alpha': 0.83636363636363631}\n",
      "0.501 (+/-0.000) for {'alpha': 0.84545454545454535}\n",
      "0.501 (+/-0.000) for {'alpha': 0.8545454545454545}\n",
      "0.501 (+/-0.000) for {'alpha': 0.86363636363636354}\n",
      "0.501 (+/-0.000) for {'alpha': 0.87272727272727268}\n",
      "0.501 (+/-0.000) for {'alpha': 0.88181818181818172}\n",
      "0.501 (+/-0.000) for {'alpha': 0.89090909090909087}\n",
      "0.501 (+/-0.000) for {'alpha': 0.89999999999999991}\n",
      "0.501 (+/-0.000) for {'alpha': 0.90909090909090906}\n",
      "0.501 (+/-0.000) for {'alpha': 0.9181818181818181}\n",
      "0.501 (+/-0.000) for {'alpha': 0.92727272727272725}\n",
      "0.501 (+/-0.000) for {'alpha': 0.93636363636363629}\n",
      "0.501 (+/-0.000) for {'alpha': 0.94545454545454544}\n",
      "0.501 (+/-0.000) for {'alpha': 0.95454545454545447}\n",
      "0.501 (+/-0.000) for {'alpha': 0.96363636363636362}\n",
      "0.501 (+/-0.000) for {'alpha': 0.97272727272727266}\n",
      "0.501 (+/-0.000) for {'alpha': 0.9818181818181817}\n",
      "0.501 (+/-0.000) for {'alpha': 0.99090909090909085}\n",
      "0.501 (+/-0.000) for {'alpha': 1.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98    194997\n",
      "          1       0.13      0.01      0.01      7376\n",
      "\n",
      "avg / total       0.93      0.96      0.95    202373\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Split the train set, test set, train class, test class\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, \n",
    "                                                 #Predictor Variables\n",
    "                                                 Y, \n",
    "                                                 #Class labels\n",
    "                                                 stratify=Y, \n",
    "                                                 #data is split in a stratified fashion, using this as the class labels\n",
    "                                                 test_size=0.34,\n",
    "                                                 #Test size is set as 34% of entire set\n",
    "                                                 random_state=28,\n",
    "                                                 # Set the randon state for spliting data  in same order\n",
    "                                                )\n",
    "\n",
    "#Pre-set parameters for the classifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "binarize_lst = list(np.arange(0.0000001,1,0.01))\n",
    "alpha_lst = list(np.linspace(0.1,1,100))\n",
    "tuned_parameters = [{\"binarize\": binarize_lst},\n",
    "                    {\"alpha\": alpha_lst}]\n",
    "\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning N.B. parameters for %s\" % score)\n",
    "    print()\n",
    "    #Find the best parameters value to the classifier by cross-validation method\n",
    "    clf = GridSearchCV(BernoulliNB(), tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
    " \n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score of Training dataset 0.961905513455\n",
      "The Score of Testing dataset 0.961911915127\n",
      " \n",
      "[[377760    761]\n",
      " [ 14204    114]]\n",
      " \n",
      "Bernoulli Naive Bayes Classifier: Specificity on Training Raw Data is  0.997989543513\n",
      "Bernoulli Naive Bayes Classifier: Sensivtivity on Training Raw Data is  0.00796200586674\n",
      " \n",
      "[[194607    390]\n",
      " [  7318     58]]\n",
      " \n",
      "Bernoulli Naive Bayes Classifier: Specificity on Testing Raw Data is  0.99799996923\n",
      "Bernoulli Naive Bayes Classifier: Sensivtivity on Testing Raw Data is  0.00786334056399\n"
     ]
    }
   ],
   "source": [
    "#Split the train set, test set, train class, test class\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(np.array(X), \n",
    "                                                 #Predictor Variables\n",
    "                                                 np.array(Y), \n",
    "                                                 #Class labels\n",
    "                                                 stratify=Y, \n",
    "                                                 #data is split in a stratified fashion, using this as the class labels\n",
    "                                                 test_size=0.34,\n",
    "                                                 #Test size is set as 34% of entire set\n",
    "                                                 random_state=28,\n",
    "                                                 # Set the randon state for spliting data  in same order\n",
    "                                                )\n",
    "clf = BernoulliNB(binarize=0.89000009999999996)\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "print(\"The Score of Training dataset\",clf.score(x_train, y_train))\n",
    "print(\"The Score of Testing dataset\",clf.score(x_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "pred_train = clf.predict(x_train)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train, pred_train) #Generate the confusion matrix\n",
    "print(cm)\n",
    "print(' ')\n",
    "\n",
    "#Class 1 means True Customers\n",
    "specificity1_train = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "sensitivity1_train = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Bernoulli Naive Bayes Classifier: Specificity on Training Raw Data is \", specificity1_train)\n",
    "print(\"Bernoulli Naive Bayes Classifier: Sensivtivity on Training Raw Data is \", sensitivity1_train)\n",
    "print(' ')\n",
    "\n",
    "#Use the SAME classifier to predict on the provided Testing Set\n",
    "pred_test = clf.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, pred_test) #Generate the confusion matrix\n",
    "print(cm)\n",
    "print(' ')\n",
    "\n",
    "#Class 1 means True Customers\n",
    "specificity1_test = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "sensitivity1_test = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Bernoulli Naive Bayes Classifier: Specificity on Testing Raw Data is \", specificity1_test)\n",
    "print(\"Bernoulli Naive Bayes Classifier: Sensivtivity on Testing Raw Data is \", sensitivity1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning KNN parameters for recall\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Split the train set, test set, train class, test class\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(np.array(X_norm), \n",
    "                                                 #Predictor Variables\n",
    "                                                 np.array(Y), \n",
    "                                                 #Class labels\n",
    "                                                 stratify=Y, \n",
    "                                                 #data is split in a stratified fashion, using this as the class labels\n",
    "                                                 test_size=0.34,\n",
    "                                                 #Test size is set as 34% of entire set\n",
    "                                                 random_state=28,\n",
    "                                                 # Set the randon state for spliting data  in same order\n",
    "                                                )\n",
    "\n",
    "#Pre-set parameters for the classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#binarize_lst = list(np.arange(0.0000001,1,0.01))\n",
    "#alpha_lst = list(np.linspace(0.1,1,100))\n",
    "n_neighbors_lst = list(np.linspace(5,10,5, dtype=np.int64))\n",
    "tuned_parameters = [{\"n_neighbors\":n_neighbors_lst}, \n",
    "                    {\"weights\":['distance']},\n",
    "                    {\"metric\":['minkowski']}]\n",
    "\n",
    "scores = ['recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning KNN parameters for %s\" % score)\n",
    "    print()\n",
    "    #Find the best parameters value to the classifier by cross-validation method\n",
    "    clf = GridSearchCV(neighbors.KNeighborsClassifier(), tuned_parameters, cv=5, scoring='%s_macro' % score)\n",
    " \n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##****Check KNN ****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df2.loc[:,\"ps_ind_01\":]\n",
    "Y2 = df2.loc[:,\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90951193  0.02546386  0.01104802  0.00704067  0.00629573  0.00609606\n",
      "  0.00530995  0.00454164  0.00361306  0.00292483]\n",
      "[[-40.23522617   3.19669802   0.88656851  -6.53140223   2.02838233\n",
      "   -3.64226821  -1.44229512  -3.4445299    1.15663363  -0.62531328]\n",
      " [ 33.76951063   4.24840968  -5.03994568   4.53360286  -1.32507927\n",
      "   -2.30169749   1.64738455   1.51723045  -2.2592173    1.85282651]\n",
      " [-40.27989154   6.49883373   4.53002852   2.43584695  -1.34797038\n",
      "   -1.54734564   1.15759172  -2.49000293  -1.90281242  -0.73220963]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+VWtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15badfc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, NMF\n",
    "n_component=10\n",
    "pca = PCA(n_components=n_component, \n",
    "          random_state = 28, \n",
    "          iterated_power=10)\n",
    "pca.fit_transform(np.array(X2))\n",
    "print(pca.explained_variance_ratio_)\n",
    "var_ratio_lst = pca.explained_variance_ratio_\n",
    "n_compo_lst = list(map(int,np.linspace(1,n_component,n_component)))\n",
    "\n",
    "plt.bar(n_compo_lst,var_ratio_lst)\n",
    "\n",
    "print(X4[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classify__C': 0.001, 'reduce_dim': PCA(copy=True, iterated_power=7, n_components=1, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), 'reduce_dim__n_components': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1190b5358>"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm8VWXZ//HPl0lQSVLJBFTInNAE5ahpajaZ0GNaaiim\nOYRhapo+pvX4KzRLy7mySM1MC3BWIg2cNYcUFMUhFA3lKCrgHDNcvz/WfbbLzRkWdNbZcPy+X6/9\nOmu4972utfY+69rrvtegiMDMzAygQ60DMDOzVYeTgpmZVTgpmJlZhZOCmZlVOCmYmVmFk4KZmVU4\nKViLJB0saWJJdW8haYqkdyV9r4xlrMokjZT05xLq3U3StNautzX9N+u+Oqzf6spJoQ1JGiZpkqT3\nJM2SdKukXWsdV0si4i8RsWdJ1f8AuCsiukfEr/6biiTdLenbrRTXakVSSPpkw3hE3BcRW5SwnL5p\nWZ1au+4VUdb6mZNCm5F0InAh8HNgA2Bj4GLgq7WMqyVt8M+/CfBUycso5L9d11rvKM1aRUT4VfIL\nWAd4DzigmTJrkCWNV9LrQmCNNG8PoJ7sV/XrwCxgX2AI8CzwBvCjXF0jgeuAq4F3gUeBAbn5pwLP\np3lPA1/LzTsMuB+4AJgLnJmm/SNXJoARwHPAW2TJTWleR+A8YA7wb+DYVL5TI+t8J7AUWJC2z+Zp\nO5wLvAS8BowCuqXyHwXGA7OBN9NwnzTvZ1V1/QboW71s4G7g202ta5p+BPBMWsYEYJMmPrOG+o9M\n8d6bpn8aeCBtm8eBPXLv6Qfck7b9bSnOP+c/56plzAC+mNu2P8p9dpOBjYB7Uxz/Ses+tLouYKu0\n7m+RJeGv5uZdkT7Dv6V6/wls2sQ6v5SW9V567dzSNgO2Tuv6RvpMf5T7nl4DXJmW+xRQV7Xu/ws8\nAbxN9n3u2ti2ArYj+56/m8qNzX2eh5H7/ua+w5/M/e819Z1bn+x79laK/z6gQ633KaXur2odwIfh\nBewFLKGRHWOuzBnAQ8DHgJ5pp/LTNG+P9P4fA52B4WQ7xtFA9/RPNx/ol8qPBBYD+6fy/0u2g+6c\n5h8A9CI7UhyadiYbpnmHpWUdB3QCulX/U6V/qPFAD7IjntnAXmneCLJE04dsJ347TSSFVP5u0k46\njV8AjAPWTev2V+CsNG89YD9gzTTvWuCmZurqW71slk8K1eu6DzCdbCfaCTgNeKCJ2BvqvxJYK72/\nN1mCGZK275fSeM/0ngeB88l2RLuT7cSKJoWTganAFoCAAcB6uc/kk7n3VepK34HpZAmlC/D5tNwt\n0vwrUow7pnX+CzC2hXXOb9Mmt1n6nGYBJwFd0/hOue/pgrStOgJnAQ9VrfvDZN/VdcmSzohG1q8L\n8CLw/bSu+5N9/4smhea+c2eRJYnO6bUb6QdQe33VPIAPwws4GHi1hTLPA0Ny418GZqThPch2+h3T\nePf0pd4pV34ysG8aHln1z9Uh/WPu1sSypwD7pOHDgJeq5n/gnyote9fc+DXAqWn4TuA7uXlfrN6J\nVNV9N+/vpEWWoDbNzd8Z+HcT7x0IvNlYXWm8b/WyWT4pVK/rrcCRVdtuHo0cLeTq/0Ru2inAVVXl\nJgDfIkugS4C1cvNGUzwpTGv4nBqJpbmksBvwKrlfuMAYYGQavgK4LDdvCPCvJpbT2DZtcpsBBwGP\nNVHXSOD23Hh/YH7Vun8zN/5LYFQj67c72dG1cmUfoEBSaOk7R/Zj7eb8tm3vL/cptI25wPottDn3\nIvu10+DFNK1SR0QsTcPz09/XcvPnA2vnxmc2DETEMrLmp14Akg5NZ/y8JektYBuyw+Tl3tuMV3PD\n83LL7lX1/iJ1NehJdhQwORfb39N0JK0p6feSXpT0DlmzSQ9JHVdgGdWq49sEuCi3/DfIdhy9C9ax\nCXBAw/tTHbsCG5Jtmzcj4j+58vnPvCUbkf14WFG9gJnpe5Bfbn6dmvo8i2hum7UUc/Vyu1b9nxSJ\nqxfwcqS9eFJ0uzb7nQPOITsKmijpBUmnFqx3teWk0DYeBBaS9QM05RWyf64GG6dpK2ujhgFJHcia\nc16RtAlwKVlb/3oR0QN4kuyfuEH+n2tFzUrLWi6OAuaQJbetI6JHeq0TEQ07gpPImk52ioiPkP1C\nhPdjr467Yee7Zm7ax6vKVL9nJtmRTo/cq1tEPNBM3Pk6ZpIdKeTfv1ZEnE22bT4qaa1c+Y2r4q3E\nmpJdz9z8mcCmzcTRlFeAjdL3IL/cl1eirsa+G81ts5nAJ1ZiOStiFtBbUv473Nx2zX8Hmv3ORcS7\nEXFSRHyC7KSQEyV9obQ1WQU4KbSBiHibrD/gYkn7pl+8nSUNlvTLVGwMcJqknpLWT+X/m/PXB0n6\nevrVdQJZUnqIrO07yPoBkHQ42ZFCa7kGOF5Sb0k9yJpTCkm/ZC8FLpD0sRRfb0lfTkW6k/0DvyVp\nXeAnVVW8Rm4HFBGzyXZ835TUUdIRtLxTHQX8UNLWafnrSDqg6DqQfWZ7S/pyWmZXSXtI6hMRLwKT\ngNMldUmnI++de++zZL+UvyKpM1nb/Bq5+ZcBP5W0mTLbSlqvsXWv8k+yX9k/SN+7PdJyx67AejWY\nDSyrWlZz22w8sKGkEyStIam7pJ1WYrnNeZCsWe57af2+TtY/0uBxYGtJAyV1JWu2Alr+zkn6H0mf\nTAnnbbKTGfJHXO2Ok0IbiYjzgBPJ/tFnk/2COha4KRU5k2yH8QRZZ+KjadrKupmsE/lN4BDg6xGx\nOCKeJjs76EGyHcmnyM7AaS2XAhPJ1uMx4Bayf9ilzb0p5xSyw/WHUhPR7WRHB5CdkdWN7NfdQ2SH\n+XkXAftLelNSwzUPw8k6aOeSdcg394ufiLgR+AUwNi3/SWBwwdiJiJlkHa8/4v3P+WTe/18bBuxE\n1sTyE7JO6ob3vg18l2zn/zLZL9z6XPXnkyXdicA7wB/ItgdkO7o/pSaQb1TFtIgsCQwm23a/BQ6N\niH8VXa9cXfPIzvS6Py3r081ts4h4l6yzfW+ypqDngM+t6HJbiGkR8HWyvoM3yL73N+TmP0vWN3B7\nWv4/qqpo7ju3WRp/j+x/5rcRcVdrxr+qaTiN0NoRSSPJOsa+uQrEMpisc3CTFgubtRJJV5B1RJ9W\n61hWNz5SsFYlqZukIZI6SepN9mv4xlrHZWbFlJYUJF0u6XVJTzYxX5J+JWm6pCckbV9WLNamBJxO\n1mz1GNm55T+uaURmVlhpzUeSdidrh7syIpbryJQ0hOyioSFkbawXRURrd0CZmdkKKO1IISLuJev0\naco+ZAkjIuIhsvPNNywrHjMza1ktb+DVmw9e9FOfps2qLijpKOAogLXWWmvQlltu2SYBmpm1F5Mn\nT54TET1bKrda3NUxIi4BLgGoq6uLSZMm1TgiM7PVi6RCV3nX8uyjl/ng1a59WLkrLM3MrJXUMimM\nAw5NZyF9Gng7IpZrOjIzs7ZTWvORpDFkdzJcX1I92fnqnQEiYhTZla5DyK4knAccXlYsZmZWTGlJ\nISIOamF+AMe0xrIWL15MfX09CxYsaI3qrICuXbvSp08fOnfuXOtQzKwVrRYdzS2pr6+ne/fu9O3b\nlw/eKNHKEBHMnTuX+vp6+vXrV+twzKwVtYvbXCxYsID11lvPCaGNSGK99dbzkZlZO9QujhSAQgnB\nZ7K2JjFnDvTvX+s4Ws+qcm9Ine4fN9a4+En5X9J2caRgZmato90cKeS1divSI4+0XGannTqy6aaf\nYunSJfTrtxUjR/6Jrl3XZM6cVzn//BN4+ulH6N69B+uuuwEnnnghm2yyOQCjR1/IxRefyoQJr7H2\n2uu0buBmZivIRwqtZI01ujF69BSuvvpJOnXqwvXXjyIi+MEPvsagQXtw003Pc9VVkznmmLN44433\nH608ceIY+vffgTvvvKGZ2s3M2oaTQgm22243Zs6czqRJd9GpU2f2229EZd7mmw9gu+12A6C+/nnm\nzXuPESPOZOLEMbUK18yswkmhlS1ZsoQHHriVT37yUzz//JNsueWgJstOnDiWPfc8kO22240XX5zG\n3LmvNVnWzKwtOCm0koUL5zNs2EAOPbSOj398Y/bZ58gW3zNhwhj23PNAOnTowOc/vx933HFtG0Rq\nZta0dtnRXAsNfQp5n/jE1tx553WNlp8+fSozZz7Hscd+CYDFixfRq1c/vvGNY0uP1cysKT5SKNEO\nO3yeRYsWcsMNl1SmPffcEzz22H1MmDCG4cNHMm7cDMaNm8Gtt77CnDmvMGtWobvbmpmVol0eKTR1\nEVJbX7wmiXPOuZHzzz+BK6/8BV26dKVXr76ceOKFTJw4losuuuUD5ffY42tMnDiWb33rlLYN1Mws\naZdJoRbuvfe9Rqf37NmLs866ZrnpN9/8wnLTvv/981s9LjOzFeHmIzMzq3BSMDOzCicFMzOrcFIw\nM7MKJwUzM6twUjAzs4p2eUpqaz+k5JGvrCJPXzEzK5mPFFrJ7ruvXRm+//5b2G+/zZk160UuuWQk\nQ4b0Ztiwgey//5acffbRLFu2bIXrnzZtCvff/8GL3e6++yYuvfSMJt/zyiszGDp0m0bnjRr1Y/75\nz9sBOO20g9lvvy0YOnQbzjjjCJYsWQzAffeNZ9SoH69wrGa2+nJSaGUPP3wH5577PS666FY23HAT\nAA466PuMHj2Fa655munTp/Loo/escL3PPrt8Urjyyl9ywAHfXak4R4w4g512+iIAgwcfzHXX/Yux\nY6eycOF8brrpMgB23fUr3HffX1mwYN5KLcPMVj9OCq3o0Ufv5Wc/G84FF4ynT59Nl5u/ePEiFi1a\nQPfuHwWy5ykcd9xeHHLIIIYP340ZM/4FwO23X8vQodswbNgAjjpqdxYvXsTvf/9jbrvtaoYNG8jE\niVfz4ovP0qXLGvTosT4Ac+e+xsknf41hwwYwbNgAHn/8AQCWLVvKmWcO5xvf2Jpjj92TBQvmAzBy\n5GHccUd2s77PfGYIkpDE1lvvyOuv1wPZbToGDdqD++4bX+6GM7NVhpNCK1m0aCEnn7wv5557E337\nbvmBeWPGXMCwYQMZPHhDNt54c7bYYiAAP/vZUZx88q+56qrJHH/8ufziF9mv/ssuO4Nf/3oCo0c/\nznnnjaNz5y585ztn8KUvDWX06CnsuedQHn/8frbYYvvKMs4993tst91nGT36ca666lE23XRrAGbO\nfI4DDjiGa655iu7de3Dnndc3uQ5LlizmlluuYued96pM22qrOqZMua/VtpOZrdqcFFpJp06d2Xbb\nXbj55j8sN6+h+WjixNeZP/8/TJw4lnnz3mPq1Ac49dQDGDZsID//+XeYM2cWAAMGfIbTTz+MG2+8\nlKVLlza6vLlzZ/HRj/asjE+adCf77380AB07dqw877lXr36VJLTlloOYNWtGk+tw9tnfZbvtdq88\nGQ5g3XU/xuzZr6zIpjCz1ZiTQivp0KEDZ511DU8//TB//OPPGy3TqVNndt55Lx599F6WLVvG2mv3\nYPToKZXXtdc+A8APfziKo48+k9dem8mhhw7irbfmLlfXGmt0Y9GiBS3G1bnzGrkYO7J06ZJGy116\n6em89dbs5W7Kt3DhAtZYo1uLyzGz9qFdnpIaP2n8FNKyb53dteuaXHDB3xg+fDfWXXeD5Z6+FhGp\n2Wc71l77I/Tq1Y/bb7+WL37xACKC5557gs03H0B9/fNss81ObLPNTjzwwK289tpM1lqrO/PmvVup\nq2/frbj11j9XxnfY4Qtcd93vGDbsBJYuXcr8+Y3ftbUxN910GQ8+OIHf/vYOOnT44O+El156lk03\nbfwMJjNrf3yk0MrWWWddfvWrv3P55Wdyzz3jgPf7FIYO3YZly5ay//5Z38FPf/oXbr75DwwbNoCh\nQ7fmnntuBuCii07mwAM/xdCh27Dttruw+eYDGDToc7zwwtOVjubtt9+dadMeI9LDI0466SImT76L\nAw/8FIccMogXXni6cMxnnz2CN954jSOO2JlhwwZ+4DTXyZPvYtddv9Jam8fMVnGKpp5Is4qqq6uL\nSVU/+Z955hm22mqrFt/b1g/ZKdu55x7PbrvtXTm1tLXNnfsap502jN/97o5G58+Z8wyDB7e83VcX\nq8q/QmtffGntR1OtIEVImhwRdS2V85HCauzww39U6jUEr776EieccF5p9ZvZqqfd9ClEBNKH6xfW\neuttwGc/+9XS6t966x2amRusxIXZZraKaxdHCl27dmXu3Lmsbk1hq69gyZK5TJ/etdaBmFkraxdH\nCn369KG+vp7Zs2c3W27OnDYKqJ1btgymT+/KyJF9ah2KmbWydpEUOnfuTL9+/Vos179/GwRjZrYa\naxfNR2Zm1jpKTQqS9pI0TdJ0Sac2Mn8dSX+V9LikpyQdXmY8ZmbWvNKSgqSOwMXAYKA/cJCk6gac\nY4CnI2IAsAdwnqQuZcVkZmbNK/NIYUdgekS8EBGLgLHAPlVlAuiu7FzStYE3gMZvzmNmZqUrMyn0\nBmbmxuvTtLzfAFsBrwBTgeMjYrmz3yUdJWmSpEktnWFkZmYrr9YdzV8GpgC9gIHAbyR9pLpQRFwS\nEXURUdezZ8/q2WZm1krKTAovAxvlxvukaXmHAzdEZjrwb2BLzMysJspMCo8Am0nqlzqPDwTGVZV5\nCfgCgKQNgC2AF0qMyczMmlHaxWsRsUTSscAEoCNweUQ8JWlEmj8K+ClwhaSpgIBTIsLXHZuZ1Uip\nVzRHxC3ALVXTRuWGXwH2LDMGMzMrrtYdzWZmtgpxUjAzswonBTMzq2gxKUjaW5KTh5nZh0CRnf1Q\n4DlJv5TkawjMzNqxFpNCRHwT2A54nuz00QfTbSe6lx6dmZm1qULNQhHxDnAd2U3tNgS+Bjwq6bgS\nYzMzszZWpE/hq5JuBO4GOgM7RsRgYABwUrnhmZlZWypy8dp+wAURcW9+YkTMk3RkOWGZmVktFEkK\nI4FZDSOSugEbRMSMiLijrMDMzKztFelTuBbIP+NgaZpmZmbtTJGk0Ck9OQ2ANOxHZpqZtUNFksJs\nSV9tGJG0D+A7mZqZtUNF+hRGAH+R9Buy21vPBA4tNSozM6uJFpNCRDwPfFrS2mn8vdKjMjOzmij0\nPAVJXwG2BrpKAiAizigxLjMzq4EiF6+NIrv/0XFkzUcHAJuUHJeZmdVAkY7mXSLiUODNiDgd2BnY\nvNywzMysFookhQXp7zxJvYDFZPc/MjOzdqZIn8JfJfUAzgEeBQK4tNSozMysJppNCunhOndExFvA\n9ZLGA10j4u02ic7MzNpUs81HEbEMuDg3vtAJwcys/SrSp3CHpP3UcC6qmZm1W0WSwnfIboC3UNI7\nkt6V9E7JcZmZWQ0UuaLZj900M/uQaDEpSNq9senVD90xM7PVX5FTUk/ODXcFdgQmA58vJSIzM6uZ\nIs1He+fHJW0EXFhaRGZmVjNFOpqr1QNbtXYgZmZWe0X6FH5NdhUzZElkINmVzWZm1s4U6VOYlBte\nAoyJiPtLisfMzGqoSFK4DlgQEUsBJHWUtGZEzCs3NDMza2uFrmgGuuXGuwG3lxOOmZnVUpGk0DX/\nCM40vGZ5IZmZWa0USQr/kbR9w4ikQcD8IpVL2kvSNEnTJZ3aRJk9JE2R9JSke4qFbWZmZSjSp3AC\ncK2kV8gex/lxssdzNktSR7I7rH6J7DTWRySNi4inc2V6AL8F9oqIlyR9bCXWwczMWkmRi9cekbQl\nsEWaNC0iFheoe0dgekS8ACBpLLAP8HSuzDDghoh4KS3r9RUJ3szMWleLzUeSjgHWiognI+JJYG1J\n3y1Qd29gZm68Pk3L2xz4qKS7JU2WdGgTMRwlaZKkSbNnzy6waDMzWxlF+hSGpyevARARbwLDW2n5\nnYBBwFeALwP/T9Lm1YUi4pKIqIuIup49e7bSos3MrFqRPoWOkhQRAZW+gi4F3vcysFFuvE+allcP\nzI2I/5B1aN8LDACeLVC/mZm1siJHCn8Hrpb0BUlfAMakaS15BNhMUj9JXYADgXFVZW4GdpXUSdKa\nwE7AM8XDNzOz1lTkSOEUsqevHZ3GbwMua+lNEbFE0rHABKAjcHlEPCVpRJo/KiKekfR34AlgGXBZ\n6rcwM7MaUGoVWm3U1dXFpEmTWi7YCD9l2pqzqvwr6HR/Ua1x8ZOV/5JKmhwRdS2VK3KX1M2As4D+\nZA/ZyYKL+MRKR2dmZqukIn0KfwR+R3aH1M8BVwJ/LjMoMzOrjSJJoVtE3EHW1PRiRIwkO4XUzMza\nmSIdzQsldQCeSx3HLwNrlxuWmZnVQpEjhePJ7or6PbILzb4JfKvMoMzMrDYK3fsoDb4HHF5uOGZm\nVktFjhTMzOxDwknBzMwqnBTMzKyiyMVrPcnuito3Xz4ijigvLDMzq4Uip6TeDNwH3A4sLTccMzOr\npSJJYc2IOKX0SMzMrOaK9CmMlzSk9EjMzKzmil68Nl7SAknvptc7ZQdmZmZtr8jFa93bIhAzM6u9\nIn0KSPoqsHsavTsixpcXkpmZ1UqLzUeSziZrQno6vY6XdFbZgZmZWdsrcqQwBBgYEcsAJP0JeAz4\nYZmBmZlZ2yt6RXOP3PA6ZQRiZma1V+RI4SzgMUl3ASLrWzi11KjMzKwmipx9NEbS3cAOadIpEfFq\nqVGZmVlNNNl8JGnL9Hd7YEOgPr16pWlmZtbONHekcCJwFHBeI/MC+HwpEZmZWc00mRQi4qg0ODgi\nFuTnSepaalRmZlYTRc4+eqDgNDMzW801eaQg6eNAb6CbpO3IzjwC+AiwZhvEZmZmbay5PoUvA4cB\nfYDzc9PfBX5UYkxmZlYjzfUp/An4k6T9IuL6NozJzMxqpMh1CtdL+gqwNdA1N/2MMgMzM7O2V+SG\neKOAocBxZP0KBwCblByXmZnVQJGzj3aJiEOBNyPidGBnYPNywzIzs1ookhTmp7/zJPUCFpNd4Wxm\nZu1MkRvijZfUAzgHeJTsaubLSo3KzMxqokhH80/T4PWSxgNdI+LtcsMyM7NaKNLRfEw6UiAiFgId\nJH239MjMzKzNFelTGB4RbzWMRMSbwPAilUvaS9I0SdMlNfkMBkk7SFoiaf8i9ZqZWTmKJIWOkhpu\ncYGkjkCXlt6Uyl0MDAb6AwdJ6t9EuV8AE4sGbWZm5SiSFP4OXC3pC5K+AIxJ01qyIzA9Il6IiEXA\nWGCfRsodB1wPvF4wZjMzK0mRs49OAb4DHJ3Gb6PY2Ue9gZm58Xpgp3wBSb2BrwGf4/0nuy1H0lFk\nz3Zg4403LrBoMzNbGUXOPloG/C69WtuFZI/3XJZroWoshkuASwDq6uqihDjMzIzmb519TUR8Q9JU\nsmsTPiAitm2h7peBjXLjfdK0vDpgbEoI6wNDJC2JiJuKBG9mZq2ruSOFE9Lf/1nJuh8BNpPUjywZ\nHAgMyxeIiH4Nw5KuAMY7IZiZ1U5zSWE8sD1wZkQcsqIVR8QSSccCE4COwOUR8ZSkEWn+qJUJ2MzM\nytNcUugiaRiwi6SvV8+MiBtaqjwibgFuqZrWaDKIiMNaqs/MzMrVXFIYARwM9AD2rpoXQItJwczM\nVi/NPXntH8A/JE2KiD+0YUxmZlYjzZ199PmIuBN4c2Wbj8zMbPXSXPPRZ4E7Wb7pCNx8ZGbWLjXX\nfPST9PfwtgvHzMxqqcits4+X9BFlLpP0qKQ92yI4MzNrW0VuiHdERLwD7AmsBxwCnF1qVGZmVhNF\nkkLDTYmGAFdGxFO5aWZm1o4USQqTJU0kSwoTJHUHlpUblpmZ1UKRW2cfCQwEXoiIeZLWBdz5bGbW\nDhU5UtgZmBYRb0n6JnAa8Ha5YZmZWS0USQq/A+ZJGgCcBDwPXFlqVGZmVhNFksKSiAiyR2n+JiIu\nBrqXG5aZmdVCkT6FdyX9EPgmsLukDkDncsMyM7NaKHKkMBRYCBwZEa+SPUHtnFKjMjOzmijyjOZX\ngfNz4y/hPgUzs3apyG0uPi3pEUnvSVokaakkn31kZtYOFWk++g1wEPAc0A34NvDbMoMyM7PaKJIU\niIjpQMeIWBoRfwT2KjcsMzOrhSJnH82T1AWYIumXwCwKJhMzM1u9FNm5HwJ0BI4F/gNsBOxXZlBm\nZlYbRc4+ejENzgdOLzccMzOrpeae0TyV7LGbjYqIbUuJyMzMaqa5I4X/abMozMxsldBcUugMbBAR\n9+cnSvoM8GqpUZmZWU0019F8IfBOI9PfSfPMzKydaS4pbBARU6snpml9S4vIzMxqprmk0KOZed1a\nOxAzM6u95pLCJEnDqydK+jYwubyQzMysVprraD4BuFHSwbyfBOqALsDXyg7MzMzaXpNJISJeA3aR\n9DlgmzT5bxFxZ5tEZmZmba7IFc13AXe1QSxmZlZjvrGdmZlVOCmYmVlFqUlB0l6SpkmaLunURuYf\nLOkJSVMlPSBpQJnxmJlZ80pLCpI6AhcDg4H+wEGS+lcV+zfw2Yj4FPBT4JKy4jEzs5aVeaSwIzA9\nIl6IiEXAWGCffIGIeCAi3kyjDwF9SozHzMxaUGZS6A3MzI3Xp2lNORK4tbEZko6SNEnSpNmzZ7di\niGZmlrdKdDSnayGOBE5pbH5EXBIRdRFR17Nnz7YNzszsQ6TIM5pX1stkj+5s0CdN+wBJ2wKXAYMj\nYm6J8ZiZWQvKPFJ4BNhMUj9JXYADgXH5ApI2Bm4ADomIZ0uMxczMCijtSCEilkg6FpgAdAQuj4in\nJI1I80cBPwbWA34rCWBJRNSVFZOZmTWvzOYjIuIW4JaqaaNyw98Gvl1mDGZmVtwq0dFsZmarBicF\nMzOrcFIwM7MKJwUzM6twUjAzswonBTMzq3BSMDOzCicFMzOrcFIwM7MKJwUzM6twUjAzswonBTMz\nq3BSMDOzCicFMzOrcFIwM7MKJwUzM6twUjAzswonBTMzq3BSMDOzCicFMzOrcFIwM7MKJwUzM6tw\nUjAzswonBTMzq3BSMDOzCicFMzOrcFIwM7MKJwUzM6twUjAzswonBTMzq3BSMDOzCicFMzOrcFIw\nM7MKJwUzM6twUjAzs4pSk4KkvSRNkzRd0qmNzJekX6X5T0javsx4zMyseaUlBUkdgYuBwUB/4CBJ\n/auKDQZHDiUaAAAGOUlEQVQ2S6+jgN+VFY+ZmbWszCOFHYHpEfFCRCwCxgL7VJXZB7gyMg8BPSRt\nWGJMZmbWjE4l1t0bmJkbrwd2KlCmNzArX0jSUWRHEgDvSZrWuqGagVTrCKwR6wNzah3EqkIj/6sv\n6SZFCpWZFFpNRFwCXFLrOMysbUmaFBF1tY7jw6TM5qOXgY1y433StBUtY2ZmbaTMpPAIsJmkfpK6\nAAcC46rKjAMOTWchfRp4OyJmVVdkZmZto7Tmo4hYIulYYALQEbg8Ip6SNCLNHwXcAgwBpgPzgMPL\nisfMVktuNm5jiohax2BmZqsIX9FsZmYVTgpmZlbhpGBmqxxJl0t6XdKTtY7lw8ZJwcxWRVcAe9U6\niA8jJwUzW+VExL3AG7WO48PIScHMzCqcFMzMrMJJwczMKpwUzMyswknBzFY5ksYADwJbSKqXdGSt\nY/qw8G0uzMyswkcKZmZW4aRgZmYVTgpmZlbhpGBmZhVOCmZmVuGkYCtM0lJJUyQ9Kemvknqs4PtH\nSvrfEuPr29Z315Q0Q9L6bbCccyQ9JemcqulrSLo9fS5DV6LefSX1b71IbXXlpGArY35EDIyIbchu\nWnZMrQNanUlakcfiHgVsGxEnV03fDiB9LlevRBj7AiuUFFYwbltNOCnYf+tBoHfDiKSTJT0i6QlJ\np+em/5+kZyX9A9giN/1uSXVpeH1JM9JwR0nnpqORJyQdl6YPknSPpMmSJkjaMDf9cUmP00SSkrRH\nWt51kv4l6S+SlOZVfulLqpN0dxoeKelPku6T9KKkr0v6paSpkv4uqXNuET9I0x+W9Mn0/p6Srk/b\n5BFJn8nVe5Wk+4GrquJUOiJ4MtU3NE0fB6wNTM4fDUj6GPBnYId0pLBpM9tpeIrj8RTXmpJ2Ab4K\nnJN7f1Ofy2GSxkm6E7ijqc9c0lqS/paW8+TKHL1YjUSEX36t0At4L/3tCFwL7JXG9yR70LrIfnCM\nB3YHBgFTgTWBjwDTgf9N77kbqEvD6wMz0vDRwHVApzS+LtAZeADomaYNBS5Pw08Au6fhc4AnG4l7\nD+BtoE+K70Fg1zRvBrB+Gq4D7k7DI4F/pGUPAOYBg9O8G4F9c+//vzR8KDA+DY/OLWNj4JlcvZOB\nbo3EuR9wW9q+GwAvARvmt30T69awzOa203q595wJHJeGrwD2z81r6nM5DKgH1m3hM98PuDRX3zq1\n/t76Vezlwz9bGd0kTSE7QniGbAcG2Q5iT+CxNL42sBnQHbgxIuZB5RdvS74IjIqIJQAR8YakbYBt\ngNvSD/yOwKzUp9EjsnvwQ/bLe3AT9T4cEfUpjilAX7KdfnNujYjFkqamZf49TZ+a3t9gTO7vBbn1\n6J/iBfiIpLXT8LiImN/I8nYFxkTEUuA1SfcAOwBFthtkR2LLbac0bxtJZwI9yD6fCQXrzLstIhqe\nddDUZ34fcJ6kX5Alq/tWYjlWA04KtjLmR8RASWuS7VSOAX5F9mvxrIj4fb6wpBOaqWsJ7zdjdm1h\nuQKeioidq+pfkY7uhbnhpbz/P9BcHAsBImKZpMWRfvoCy/jg/1A0MtwB+HRELKiKGeA/KxD3imh0\nOyVXkB3dPC7pMLIjjMY0tz3ycTf6mQNI2h4YApwp6Y6IOKPwGljNuE/BVlr65f894KTU6TgBOKLh\nl7Ck3qm9+15gX0ndJHUH9s5VM4OseQlg/9z024DvpHqRtC4wDegpaec0rbOkrSPiLeAtSbum9x68\nEquTj2O/lXg/ZM00DX8fTMMTgeMaCkgaWKCe+4ChqV+lJ1lzzMMrEEej2ynN6052dNWZD26nd9O8\nBjNo/HOp1uhnLqkXMC8i/kzWnLf9CsRvNeSkYP+ViHiMrD3/oIiYSNaG/mBqarkO6B4RjwJXA48D\ntwKP5Ko4Fzha0mNkbdcNLiNrS38idR4Pi4hFZDuoX6RpU4BdUvnDgYtTk5BYcacDF0maRHYEsTI+\nKukJ4Hjg+2na94C61An7NDCiQD03km3Tx4E7gR9ExKtFg2hhO/0/4J/A/cC/cm8bC5ws6TFJm9L0\n51K9rEY/c+BTwMPp8/gJWf+FrQZ8l1QzM6vwkYKZmVU4KZiZWYWTgpmZVTgpmJlZhZOCmZlVOCmY\nmVmFk4KZmVX8f7n5fW9VrdGfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1137b0710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "pipe = Pipeline([('reduce_dim', PCA()),\n",
    "                 ('classify', LinearSVC())])\n",
    "\n",
    "#N_FEATURES_OPTIONS = [2, 4, 8]\n",
    "N_FEATURES_OPTIONS = [1]\n",
    "#C_OPTIONS = [1, 10, 100, 1000]\n",
    "C_OPTIONS = [0.001]\n",
    "#kernel_Option = [\"linear\",\"rbf\",\"poly\"]\n",
    "\n",
    "param_grid = [{'reduce_dim': [PCA(iterated_power=7)],\n",
    "               'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "               'classify__C': C_OPTIONS},\n",
    "              {'reduce_dim': [SelectKBest(chi2)],\n",
    "               'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "               'classify__C': C_OPTIONS}]\n",
    "\n",
    "#reducer_labels = ['PCA', 'NMF', 'KBest(chi2)']\n",
    "reducer_labels = ['PCA',  'KBest(chi2)']\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=3, n_jobs=1, param_grid=param_grid) #Use Recall as scoring method\n",
    "digits = load_digits()\n",
    "grid.fit(np.array(X2), np.array(Y2))\n",
    "\n",
    "print(grid.best_params_)\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "# scores are in the order of param_grid iteration, which is alphabetical\n",
    "mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# select score for best C\n",
    "mean_scores = mean_scores.max(axis=0)\n",
    "bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *(len(reducer_labels) + 1) + .5)\n",
    "\n",
    "plt.figure()\n",
    "COLORS = 'bgrcmyk'\n",
    "for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n",
    "    plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])\n",
    "\n",
    "plt.title(\"Comparing feature reduction techniques\")\n",
    "plt.xlabel('Reduced number of features')\n",
    "plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 573518, 1: 21694})\n",
      "Resampled dataset shape Counter({0: 573518, 1: 400000})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "print('Original dataset shape {}'.format(Counter(Y2)))\n",
    "#sm = SMOTE(ratio = {1:400000},random_state=42)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, Y_res = sm.fit_sample(X2, Y2)\n",
    "print('Resampled dataset shape {}'.format(Counter(Y_res)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score of Training dataset 0.963552498606\n",
      "The Score of Testing dataset 0.963552450179\n",
      " \n",
      "[[378521      0]\n",
      " [ 14318      0]]\n",
      " \n",
      "Bernoulli Naive Bayes Classifier: Specificity on Training Raw Data is  1.0\n",
      "Bernoulli Naive Bayes Classifier: Sensivtivity on Training Raw Data is  0.0\n",
      " \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-471-483fdb9ed3a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#Use the SAME classifier to predict on the provided Testing Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Generate the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \"\"\"\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Split the train set, test set, train class, test class\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(np.array(X_res), \n",
    "                                                 #Predictor Variables\n",
    "                                                 np.array(Y_res), \n",
    "                                                 #Class labels\n",
    "                                                 stratify=Y, \n",
    "                                                 #data is split in a stratified fashion, using this as the class labels\n",
    "                                                 test_size=0.34,\n",
    "                                                 #Test size is set as 34% of entire set\n",
    "                                                 random_state=28\n",
    "                                                 # Set the randon state for spliting data  in same order\n",
    "                                                )\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pca=PCA(n_components=5)\n",
    "pca.fit(x_train)\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "clf = SVC(C=0.001, kernel = \"rbf\")\n",
    "clf.fit(x_train,y_train)\n",
    "print(\"The Score of Training dataset\",clf.score(x_train, y_train))\n",
    "print(\"The Score of Testing dataset\",clf.score(x_test, y_test))\n",
    "print(' ')\n",
    "\n",
    "clf.fit(x_train,y_train)\n",
    "pred_train = clf.predict(x_train)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train, pred_train) #Generate the confusion matrix\n",
    "print(cm)\n",
    "print(' ')\n",
    "\n",
    "#Class 1 means True Customers\n",
    "specificity1_train = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "sensitivity1_train = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Bernoulli Naive Bayes Classifier: Specificity on Training Raw Data is \", specificity1_train)\n",
    "print(\"Bernoulli Naive Bayes Classifier: Sensivtivity on Training Raw Data is \", sensitivity1_train)\n",
    "print(' ')\n",
    "\n",
    "#Use the SAME classifier to predict on the provided Testing Set\n",
    "pred_test = clf.predict(x_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, pred_test) #Generate the confusion matrix\n",
    "print(cm)\n",
    "print(' ')\n",
    "\n",
    "#Class 1 means True Customers\n",
    "specificity1_test = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "sensitivity1_test = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Bernoulli Naive Bayes Classifier: Specificity on Testing Raw Data is \", specificity1_test)\n",
    "print(\"Bernoulli Naive Bayes Classifier: Sensivtivity on Testing Raw Data is \", sensitivity1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pca=PCA(n_components=1)\n",
    "pca.fit(X3)\n",
    "X3_pca = pca.transform(X3)\n",
    "\n",
    "svc=LinearSVC(C=0.01)\n",
    "svc.fit(X3_pca, Y3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124931,)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({1: 900, 0: 100})\n",
      "Resampled dataset shape Counter({1: 900, 0: 500})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE \n",
    "X, y = make_classification(n_classes=2, class_sep=2,\n",
    "                           weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
    "                           n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "sm = SMOTE(ratio = {0:500},random_state=42)\n",
    "X_res, y_res = sm.fit_sample(X, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124931, 2)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA(n_components=2)\n",
    "X3_pca = pca.fit_transform(X3)\n",
    "X3_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2., ...,  0.,  0.,  0.],\n",
       "       [ 5.,  1.,  4., ...,  0.,  1.,  0.],\n",
       "       [ 1.,  1.,  2., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 4.,  1.,  3., ...,  0.,  1.,  0.],\n",
       "       [ 3.,  2.,  3., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  3.,  6., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function run the classifier\n",
    "def calc_params(x_train,x_test,y_train, clf):\n",
    "    model=clf\n",
    "    model = model.fit(x_train,y_train)\n",
    "    pred_train = model.predict(x_train)\n",
    "    pred_test = model.predict(x_test)\n",
    "    return pred_train, pred_test\n",
    "\n",
    "#Function to calculate the accuracy of classifier\n",
    "def calc_accuracy(pred_train, pred_test, y_train, y_test):\n",
    "    train_score = accuracy_score(y_train, pred_train)\n",
    "    test_score = accuracy_score(y_test, pred_test)\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Classifier Decision Tree with Criterion = Gini\n",
      "Mean of Score of Training Set: 100.0 %\n",
      "Mean of Score of Testing Set: 91.8682756174 %\n",
      "\n",
      "Mean of Specificity: 95.056 percent\n",
      "Mean of Sensitivity: 6.365 percent\n"
     ]
    }
   ],
   "source": [
    "train_score_lst = []\n",
    "test_score_lst = []\n",
    "specificity_lst = []\n",
    "sensitivity_lst = []\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "K=5 #Set the number of Fold Cross Validataion\n",
    "cv = KFold(len(X),K,shuffle=True, random_state=28)\n",
    "clf = tree.DecisionTreeClassifier(\"gini\") #Test on Decision Tree Classifier with default setting\n",
    "\n",
    "for i , (train,test) in enumerate(cv):\n",
    "    #Plug in the \"calc_params\" function\n",
    "    pred_train, pred_test = calc_params([X[k] for k in train],\n",
    "                                        [X[k] for k in test],\n",
    "                                        y[train], \n",
    "                                        clf)\n",
    "    #plug in the \"calc_accuracy\" function\n",
    "    train_score, test_score = calc_accuracy(pred_train, pred_test, y[train], y[test])\n",
    "    \n",
    "    #Store Accuracy of Training and Testing into lists\n",
    "    train_score_lst.append(train_score)\n",
    "    test_score_lst.append(test_score)\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    tree_cm = confusion_matrix(y[test], pred_test, labels=[0,1])\n",
    "    tree_specficity = tree_cm[0,0] / (tree_cm[0,0]+tree_cm[0,1])\n",
    "    tree_sensitivity = tree_cm[1,1] / (tree_cm[1,0]+tree_cm[1,1])\n",
    "\n",
    "    specificity_lst.append(tree_specficity)\n",
    "    sensitivity_lst.append(tree_sensitivity)\n",
    "\n",
    "print(\"Single Classifier Decision Tree with Criterion = Gini\")\n",
    "print(\"Mean of Score of Training Set:\",np.mean(train_score_lst)*100,\"%\")\n",
    "print(\"Mean of Score of Testing Set:\",np.mean(test_score_lst)*100,\"%\")\n",
    "print()\n",
    "print(\"Mean of Specificity: %0.3f percent\" % (np.mean(tree_specficity*100)))\n",
    "print(\"Mean of Sensitivity: %0.3f percent\" %(np.mean(tree_sensitivity*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Classifier Decision Tree with Criterion = Entropy\n",
      "Mean of Score of Training Set: 100.0 %\n",
      "Mean of Score of Testing Set: 92.2338593883 %\n",
      "\n",
      "Mean of Specificity: 95.472 percent\n",
      "Mean of Sensitivity: 5.433 percent\n"
     ]
    }
   ],
   "source": [
    "train_score_lst=[]\n",
    "test_score_lst=[]\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "K=5 #Set the number of Fold Cross Validataion\n",
    "cv = KFold(len(X),K,shuffle=True, random_state=28)\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\") #Test on Decision Tree Classifier with default setting\n",
    "\n",
    "for i , (train,test) in enumerate(cv):\n",
    "    #Plug in the \"calc_params\" function\n",
    "    pred_train, pred_test = calc_params([X[k] for k in train],\n",
    "                                        [X[k] for k in test],\n",
    "                                        y[train], \n",
    "                                        clf)\n",
    "    #plug in the \"calc_accuracy\" function\n",
    "    train_score, test_score = calc_accuracy(pred_train, pred_test, y[train], y[test])\n",
    "    \n",
    "    #Store Accuracy of Training and Testing into lists\n",
    "    train_score_lst.append(train_score)\n",
    "    test_score_lst.append(test_score)\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    tree_cm = confusion_matrix(y[test], pred_test, labels=[0,1])\n",
    "    tree_specficity = tree_cm[0,0] / (tree_cm[0,0]+tree_cm[0,1])\n",
    "    tree_sensitivity = tree_cm[1,1] / (tree_cm[1,0]+tree_cm[1,1])\n",
    "\n",
    "    specificity_lst.append(tree_specficity)\n",
    "    sensitivity_lst.append(tree_sensitivity)\n",
    "\n",
    "print(\"Single Classifier Decision Tree with Criterion = Entropy\")\n",
    "print(\"Mean of Score of Training Set:\",np.mean(train_score_lst)*100,\"%\")\n",
    "print(\"Mean of Score of Testing Set:\",np.mean(test_score_lst)*100,\"%\")\n",
    "print()\n",
    "print(\"Mean of Specificity: %0.3f percent\" % (np.mean(tree_specficity*100)))\n",
    "print(\"Mean of Sensitivity: %0.3f percent\" %(np.mean(tree_sensitivity*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Classifier Naive Bayes\n",
      "Mean of Score of Training Set: 90.5010737542 %\n",
      "Mean of Score of Testing Set: 90.4906144361 %\n"
     ]
    }
   ],
   "source": [
    "train_score_lst=[]\n",
    "test_score_lst=[]\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "K=5 #Set the number of Fold Cross Validataion\n",
    "cv = KFold(len(X),K,shuffle=True, random_state=28)\n",
    "clf = naive_bayes.GaussianNB() #Set up Naive Bayes classifier with ALL default setting\n",
    "\n",
    "for i , (train,test) in enumerate(cv):\n",
    "    #Plug in the \"calc_params\" function\n",
    "    pred_train, pred_test = calc_params([X[k] for k in train],\n",
    "                                        [X[k] for k in test],\n",
    "                                        y[train], \n",
    "                                        clf)\n",
    "    #plug in the \"calc_accuracy\" function\n",
    "    train_score, test_score = calc_accuracy(pred_train, pred_test, y[train], y[test])\n",
    "    \n",
    "    #Store Accuracy of Training and Testing into lists\n",
    "    train_score_lst.append(train_score)\n",
    "    test_score_lst.append(test_score)\n",
    "\n",
    "print(\"Single Classifier Naive Bayes\")\n",
    "print(\"Mean of Score of Training Set:\",np.mean(train_score_lst)*100,\"%\")\n",
    "print(\"Mean of Score of Testing Set:\",np.mean(test_score_lst)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the neigbhors and run the KNN Classifier \n",
    "n_neighbors=1\n",
    "knnclf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance',metric='minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calc_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-8ebeeaae0792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#Plug in the \"calc_params\" function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         pred_train, pred_test = calc_params([X[k] for k in train],\n\u001b[0m\u001b[1;32m     15\u001b[0m                                             \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calc_params' is not defined"
     ]
    }
   ],
   "source": [
    "train_score_lst=[]\n",
    "test_score_lst=[]\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "K=5 #Set the number of Fold Cross Validataion\n",
    "cv = KFold(len(X),K,shuffle=True, random_state=28)\n",
    "\n",
    "for n_neighbors in range(1,11):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance',metric='minkowski')\n",
    "\n",
    "\n",
    "    for i , (train,test) in enumerate(cv):\n",
    "        #Plug in the \"calc_params\" function\n",
    "        pred_train, pred_test = calc_params([X[k] for k in train],\n",
    "                                            [X[k] for k in test],\n",
    "                                            y[train], \n",
    "                                            clf)\n",
    "        #plug in the \"calc_accuracy\" function\n",
    "        train_score, test_score = calc_accuracy(pred_train, pred_test, y[train], y[test])\n",
    "\n",
    "        #Store Accuracy of Training and Testing into lists\n",
    "        train_score_lst.append(train_score)\n",
    "        test_score_lst.append(test_score)\n",
    "\n",
    "print(\"Single Classifier Naive Bayes\")\n",
    "print(\"Mean of Score of Training Set:\",np.mean(train_score_lst)*100,\"%\")\n",
    "print(\"Mean of Score of Testing Set:\",np.mean(test_score_lst)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
