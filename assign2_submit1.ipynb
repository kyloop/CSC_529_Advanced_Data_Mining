{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the csv from the web source\n",
    "wine = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",\n",
    "                   sep=\",\",header=None)\n",
    "wine.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Labels', 'Alcohol', 'Malic_acid', 'Ash', 'Alca_ash', 'Magnesium',\n",
      "       'phenols', 'Flavanoids', 'Nonflav_phenols', 'Proanthocyanins',\n",
      "       'Color_int', 'Hue', 'diluted_wines', 'Proline'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alca_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflav_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels  Alcohol  Malic_acid   Ash  Alca_ash  Magnesium  phenols  \\\n",
       "0       1    14.23        1.71  2.43      15.6        127     2.80   \n",
       "1       1    13.20        1.78  2.14      11.2        100     2.65   \n",
       "\n",
       "   Flavanoids  Nonflav_phenols  Proanthocyanins  Color_int   Hue  \\\n",
       "0        3.06             0.28             2.29       5.64  1.04   \n",
       "1        2.76             0.26             1.28       4.38  1.05   \n",
       "\n",
       "   diluted_wines  Proline  \n",
       "0           3.92     1065  \n",
       "1           3.40     1050  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naming all the columns based on the source information\n",
    "wine.columns=[\"Labels\",\"Alcohol\",\"Malic_acid\",\"Ash\",\"Alca_ash\",\"Magnesium\",\"phenols\",\n",
    "           \"Flavanoids\",\"Nonflav_phenols\",\"Proanthocyanins\",\n",
    "           \"Color_int\",\"Hue\",\"diluted_wines\",\"Proline\"]\n",
    "print(wine.columns)\n",
    "wine.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target table size is (178,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assign Target labels to a new table\n",
    "y=wine['Labels']\n",
    "print(\"Target table size is\",y.shape)\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor variables size is  (178, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alca_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflav_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic_acid   Ash  Alca_ash  Magnesium  phenols  Flavanoids  \\\n",
       "0    14.23        1.71  2.43      15.6        127     2.80        3.06   \n",
       "1    13.20        1.78  2.14      11.2        100     2.65        2.76   \n",
       "2    13.16        2.36  2.67      18.6        101     2.80        3.24   \n",
       "3    14.37        1.95  2.50      16.8        113     3.85        3.49   \n",
       "4    13.24        2.59  2.87      21.0        118     2.80        2.69   \n",
       "\n",
       "   Nonflav_phenols  Proanthocyanins  Color_int   Hue  diluted_wines  Proline  \n",
       "0             0.28             2.29       5.64  1.04           3.92     1065  \n",
       "1             0.26             1.28       4.38  1.05           3.40     1050  \n",
       "2             0.30             2.81       5.68  1.03           3.17     1185  \n",
       "3             0.24             2.18       7.80  0.86           3.45     1480  \n",
       "4             0.39             1.82       4.32  1.04           2.93      735  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=wine.ix[:,1:]\n",
    "print(\"Predictor variables size is \", X.shape)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Problem 1-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the train set, test set, train class, test class\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, #Predictor Variables\n",
    "                                                 y, #Class labels\n",
    "                                                 stratify=y, #data is split in a stratified fashion, using this as the class labels\n",
    "                                                 test_size=0.34,#Test size is set as 34% of entire set\n",
    "                                                 random_state=2) # Set the randon state for spliting data  in same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 13)\n",
      "(61, 13)\n",
      "(117,)\n",
      "(61,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Desision Tree, Naive Bayes , K-Nearest Neighors\n",
    "from sklearn import neighbors, tree, naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set up Decision Tree classifier with ALL default setting\n",
    "treeclf = tree.DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                      random_state = 28,\n",
    "                                      max_depth=3, \n",
    "                                      min_samples_leaf=2)\n",
    "#Plug in the train dataset with target class\n",
    "treeclf = treeclf.fit(x_train, y_train)\n",
    "treeclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61,)\n"
     ]
    }
   ],
   "source": [
    "#Classify the Target Class\n",
    "y_pre = treeclf.predict(x_test)\n",
    "print (y_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "#The average Accuracy score across the train instances\n",
    "print (treeclf.score(x_train, y_train)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.4426229508 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pre)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Repeat 100 times on Holdout Partition and Decision Tree Model to calculate their Means, Variances, Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_times=100 #Preset 35 times trial \n",
    "train_score_lst=[] #Preset the Train score list\n",
    "test_score_lst=[] #Preset the Test score list\n",
    "\n",
    "for i in range(1,n_times+1):\n",
    "\n",
    "    #Split the train set, test set, train class, test class\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X, #Predictor Variables\n",
    "                                                     y, #Class labels\n",
    "                                                     stratify=y, #data is split in a stratified fashion, using this as the class labels\n",
    "                                                     test_size=0.34,#Test size is set as 34% of entire set\n",
    "                                                     random_state=i) # Set the randon state for spliting data  in same order\n",
    "\n",
    "    #Set up Decision Tree classifier with the optimal setting from Assignment #1\n",
    "    treeclf = tree.DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                          random_state = 28,\n",
    "                                          max_depth=3, \n",
    "                                          min_samples_leaf=2)\n",
    "    #Plug in the train dataset with target class\n",
    "    treeclf = treeclf.fit(x_train, y_train)\n",
    "    #Predict y value on testing data\n",
    "    y_pre = treeclf.predict(x_test)\n",
    "\n",
    "    #Calculate the Accuracy Score of the Training and Testing Set\n",
    "    train_score_lst.append(treeclf.score(x_train, y_train))\n",
    "    test_score_lst.append(accuracy_score(y_test, y_pre))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 13)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Calculate the Means of Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Result:\n",
      "Mean of Accuracy of Training Data is  97.89 %\n",
      "Mean of Accuracy of Testing Data is  90.0 %\n"
     ]
    }
   ],
   "source": [
    "train_score_lst_DT = train_score_lst\n",
    "test_score_lst_DT = test_score_lst\n",
    "\n",
    "train_mean=np.mean(np.array(train_score_lst))\n",
    "test_mean=np.mean(np.array(test_score_lst))\n",
    "\n",
    "print(\"Decision Tree Result:\")\n",
    "print(\"Mean of Accuracy of Training Data is \",round(train_mean*100,2),'%')\n",
    "print(\"Mean of Accuracy of Testing Data is \",round(test_mean*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Calculate the Variances of Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Result:\n",
      "Variance of Accuracy of Training Data is  0.000266571699905\n",
      "Variance of Accuracy of Testing Data is  0.00204514915345\n"
     ]
    }
   ],
   "source": [
    "train_var = np.var(np.array(train_score_lst))\n",
    "test_var = np.var(np.array(test_score_lst))\n",
    "\n",
    "print(\"Decision Tree Result:\")\n",
    "print(\"Variance of Accuracy of Training Data is \",train_var)\n",
    "print(\"Variance of Accuracy of Testing Data is \",test_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Result:\n",
      "95 Percent Confidence Interval of Training Data is (0.953,1.005)\n",
      "90 Percent Confidence Interval of Training Data is (0.957,1.001)\n",
      "80 Percent Confidence Interval of Training Data is (0.962,0.996)\n"
     ]
    }
   ],
   "source": [
    "#p,q, n values setting\n",
    "p=train_mean\n",
    "q=1-p\n",
    "n=len(x_train)\n",
    "\n",
    "print(\"Decision Tree Result:\")\n",
    "\n",
    "#95% C.I.\n",
    "z=1.96\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"95 Percent Confidence Interval of Training Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))\n",
    "\n",
    "#90% C.I.\n",
    "z=1.65\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"90 Percent Confidence Interval of Training Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))\n",
    "\n",
    "#80%C.I.\n",
    "z=1.28\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"80 Percent Confidence Interval of Training Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Result:\n",
      "95 Percent Confidence Interval of Testing Data is (0.825,0.975)\n",
      "90 Percent Confidence Interval of Testing Data is (0.837,0.963)\n",
      "80 Percent Confidence Interval of Testing Data is (0.851,0.949)\n"
     ]
    }
   ],
   "source": [
    "#p,q, n values setting\n",
    "p=test_mean\n",
    "q=1-p\n",
    "n=len(x_test)\n",
    "\n",
    "print(\"Decision Tree Result:\")\n",
    "\n",
    "#95% C.I.\n",
    "z=1.96\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"95 Percent Confidence Interval of Testing Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))\n",
    "\n",
    "#90% C.I.\n",
    "z=1.65\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"90 Percent Confidence Interval of Testing Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))\n",
    "\n",
    "#80%C.I.\n",
    "z=1.28\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"80 Percent Confidence Interval of Testing Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Repeat 100 times on Holdout Partition and Naive Bayes Model to calculate their Means, Variances, Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_times=100 #Preset 35 times trial \n",
    "train_score_lst=[] #Preset the Train score list\n",
    "test_score_lst=[] #Preset the Test score list\n",
    "\n",
    "for i in range(1,n_times+1):\n",
    "\n",
    "    #Split the train set, test set, train class, test class\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X, #Predictor Variables\n",
    "                                                     y, #Class labels\n",
    "                                                     stratify=y, #data is split in a stratified fashion, using this as the class labels\n",
    "                                                     test_size=0.34,#Test size is set as 34% of entire set\n",
    "                                                     random_state=i) # Set the randon state for spliting data  in same order\n",
    "\n",
    "   #Set up Naive Bayes classifier with ALL default setting\n",
    "    nbclf = naive_bayes.GaussianNB()\n",
    "    #Plug in the 66% of training set of data\n",
    "    nbclf=nbclf.fit(x_train,y_train)\n",
    "    #Predict y value on testing data\n",
    "    y_pre = nbclf.predict(x_test)\n",
    "\n",
    "    #Calculate the Accuracy Score of the Training and Testing Set\n",
    "    train_score_lst.append(nbclf.score(x_train, y_train))\n",
    "    test_score_lst.append(accuracy_score(y_test, y_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Calculate the Means of Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifer Result:\n",
      "Mean of Accuracy of Training Data is  98.43 %\n",
      "Mean of Accuracy of Testing Data is  97.57 %\n"
     ]
    }
   ],
   "source": [
    "train_score_lst_nb = train_score_lst\n",
    "test_score_lst_nb = test_score_lst\n",
    "\n",
    "train_mean=np.mean(np.array(train_score_lst))\n",
    "test_mean=np.mean(np.array(test_score_lst))\n",
    "\n",
    "print(\"Naive Bayes Classifer Result:\")\n",
    "print(\"Mean of Accuracy of Training Data is \",round(train_mean*100,2),'%')\n",
    "print(\"Mean of Accuracy of Testing Data is \",round(test_mean*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Calculate the Variances of Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifer Result:\n",
      "Variance of Accuracy of Training Data is  7.1181240412e-05\n",
      "Variance of Accuracy of Testing Data is  0.000249825315775\n"
     ]
    }
   ],
   "source": [
    "train_var = np.var(np.array(train_score_lst))\n",
    "test_var = np.var(np.array(test_score_lst))\n",
    "\n",
    "print(\"Naive Bayes Classifer Result:\")\n",
    "print(\"Variance of Accuracy of Training Data is \",train_var)\n",
    "print(\"Variance of Accuracy of Testing Data is \",test_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Result:\n",
      "95 Percent Confidence Interval of Training Data is (0.962,1.007)\n",
      "90 Percent Confidence Interval of Training Data is (0.965,1.003)\n",
      "80 Percent Confidence Interval of Training Data is (0.970,0.999)\n"
     ]
    }
   ],
   "source": [
    "#p,q, n values setting\n",
    "p=train_mean\n",
    "q=1-p\n",
    "n=len(x_train)\n",
    "\n",
    "print(\"Decision Tree Result:\")\n",
    "\n",
    "#95% C.I.\n",
    "z=1.96\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"95 Percent Confidence Interval of Training Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))\n",
    "\n",
    "#90% C.I.\n",
    "z=1.65\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"90 Percent Confidence Interval of Training Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))\n",
    "\n",
    "#80%C.I.\n",
    "z=1.28\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"80 Percent Confidence Interval of Training Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Result:\n",
      "95 Percent Confidence Interval of Testing Data is (0.937,1.014)\n",
      "90 Percent Confidence Interval of Testing Data is (0.943,1.008)\n",
      "80 Percent Confidence Interval of Testing Data is (0.951,1.001)\n"
     ]
    }
   ],
   "source": [
    "#p,q, n values setting\n",
    "p=test_mean\n",
    "q=1-p\n",
    "n=len(x_test)\n",
    "\n",
    "print(\"Decision Tree Result:\")\n",
    "\n",
    "#95% C.I.\n",
    "z=1.96\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"95 Percent Confidence Interval of Testing Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))\n",
    "\n",
    "#90% C.I.\n",
    "z=1.65\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"90 Percent Confidence Interval of Testing Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))\n",
    "\n",
    "#80%C.I.\n",
    "z=1.28\n",
    "ci_left, ci_right = (p)-(z*np.sqrt(p*q/n)), (p)+(z*np.sqrt(p*q/n))\n",
    "print(\"80 Percent Confidence Interval of Testing Data is (%0.3f,%0.3f)\"%(ci_left,ci_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Problem-1-b: Paired t-test\n",
    "\n",
    "Paired t-test with the following Hypothesis:\n",
    "\n",
    "P0 (Null): Mean Accuracy of TWO Models are the SAME\n",
    "\n",
    "Pa (Alternative): Mean Accuracy of TWO Models are different from each other\n",
    "\n",
    "Based on the calculation below, we could summarize as the following:\n",
    "\n",
    "Training Set: The t-statistics is -192.38 with df=99 (Degree of Freedom) which means that the corresponding p-value is greater 0.25. With assumed 95% Confidence Interval, we could NOT reject he P0 Null hypothesis, we should collect more data for further analysis\n",
    "\n",
    "Testing Set: The t-statistics is -353.363645575 with df=99 (Degree of Freedom) which means that the corresponding p-value is greater 0.25. With assumed 95% Confidence Interval, we could NOT reject he P0 Null hypothesis, we should collect more data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Size is  (100, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT_train_score</th>\n",
       "      <th>nb_train_score</th>\n",
       "      <th>Score_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.008547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>-0.008547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>-0.017094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.008547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DT_train_score  nb_train_score  Score_Difference\n",
       "0        0.991453        0.982906          0.008547\n",
       "1        0.991453        0.965812          0.025641\n",
       "2        0.974359        0.982906         -0.008547\n",
       "3        0.957265        0.974359         -0.017094\n",
       "4        1.000000        0.991453          0.008547"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate Difference of Score of Training Data of the Decision Tree and Naive Bayes Models\n",
    "diff_score = list(map(lambda x,y: x-y, train_score_lst_DT,train_score_lst_nb))\n",
    "\n",
    "#Transform the Score lists into DataFrame\n",
    "df = pd.DataFrame(list(zip(train_score_lst_DT,train_score_lst_nb,diff_score)), \n",
    "                  columns=['DT_train_score','nb_train_score','Score_Difference'])\n",
    "print(\"Table Size is \",df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Score Difference is  -0.005384615384615371\n",
      "Variance of Score Difference is  0.0002798899949897102\n",
      "Sample size of Training Set is  100\n",
      "Degree of Freedom is  99\n",
      "Calculated t-Statistic is  -192.383274894\n"
     ]
    }
   ],
   "source": [
    "Score_mean = df['Score_Difference'].mean()\n",
    "Score_var = df['Score_Difference'].var()\n",
    "print(\"Mean of Score Difference is \",df['Score_Difference'].mean())\n",
    "print(\"Variance of Score Difference is \",df['Score_Difference'].var())\n",
    "print(\"Sample size of Training Set is \", df.shape[0])\n",
    "print(\"Degree of Freedom is \", df.shape[0]-1)\n",
    "\n",
    "#Calculate t statistic:\n",
    "t_stat = Score_mean / (Score_var/np.sqrt(df.shape[0]))\n",
    "print(\"Calculated t-Statistic is \", t_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Size is  (100, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT_test_score</th>\n",
       "      <th>nb_test_score</th>\n",
       "      <th>Score_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>-0.032787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>-0.032787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>-0.114754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>-0.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>-0.065574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DT_test_score  nb_test_score  Score_Difference\n",
       "0       0.950820       0.983607         -0.032787\n",
       "1       0.934426       0.967213         -0.032787\n",
       "2       0.852459       0.967213         -0.114754\n",
       "3       0.885246       0.950820         -0.065574\n",
       "4       0.918033       0.983607         -0.065574"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate Difference of Score of Testing Data of the Decision Tree and Naive Bayes Models\n",
    "diff_score = list(map(lambda x,y: x-y, test_score_lst_DT,test_score_lst_nb))\n",
    "\n",
    "#Transform the Score lists into DataFrame\n",
    "df = pd.DataFrame(list(zip(test_score_lst_DT,test_score_lst_nb,diff_score)), \n",
    "                  columns=['DT_test_score','nb_test_score','Score_Difference'])\n",
    "print(\"Table Size is \",df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Score Difference is  -0.07573770491803276\n",
      "Variance of Score Difference is  0.002143336075074855\n",
      "Sample size of Testing Set is  100\n",
      "Degree of Freedom is  99\n",
      "Calculated t-Statistic is  -353.363645575\n"
     ]
    }
   ],
   "source": [
    "Score_mean = df['Score_Difference'].mean()\n",
    "Score_var = df['Score_Difference'].var()\n",
    "print(\"Mean of Score Difference is \",df['Score_Difference'].mean())\n",
    "print(\"Variance of Score Difference is \",df['Score_Difference'].var())\n",
    "print(\"Sample size of Testing Set is \", df.shape[0])\n",
    "print(\"Degree of Freedom is \", df.shape[0]-1)\n",
    "\n",
    "#Calculate t statistic:\n",
    "t_stat = Score_mean / (Score_var/np.sqrt(df.shape[0]))\n",
    "print(\"Calculated t-Statistic is \", t_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Problem-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size_lst = np.arange(0.25,0.86,0.1)\n",
    "DT_train_score_lst=[] #Preset the Train score list\n",
    "DT_test_score_lst=[] #Preset the Test score list\n",
    "\n",
    "for i in train_size_lst:\n",
    "\n",
    "    #Split the train set, test set, train class, test class\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X, #Predictor Variables\n",
    "                                                     y, #Class labels\n",
    "                                                     stratify=y, #data is split in a stratified fashion, using this as the class labels\n",
    "                                                     test_size=1-i,#Test size is set as 34% of entire set\n",
    "                                                     random_state=28) # Set the randon state for spliting data  in same order\n",
    "\n",
    "    #Set up Decision Tree classifier with the optimal setting from Assignment #1\n",
    "    treeclf = tree.DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                          random_state = 28,\n",
    "                                          max_depth=3, \n",
    "                                          min_samples_leaf=2)\n",
    "    #Plug in the train dataset with target class\n",
    "    treeclf = treeclf.fit(x_train, y_train)\n",
    "    #Predict y value on testing data\n",
    "    y_pre = treeclf.predict(x_test)\n",
    "\n",
    "    #Calculate the Accuracy Score of the Training and Testing Set\n",
    "    DT_train_score_lst.append(treeclf.score(x_train, y_train))\n",
    "    DT_test_score_lst.append(accuracy_score(y_test, y_pre))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95454545454545459,\n",
       " 0.967741935483871,\n",
       " 0.98750000000000004,\n",
       " 0.98969072164948457,\n",
       " 0.99130434782608701,\n",
       " 0.99248120300751874,\n",
       " 0.99337748344370858]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_train_score_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.79104477611940294,\n",
       " 0.87068965517241381,\n",
       " 0.9285714285714286,\n",
       " 0.9135802469135802,\n",
       " 0.95238095238095233,\n",
       " 0.9555555555555556,\n",
       " 0.92592592592592593]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_test_score_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size_lst = np.arange(0.25,0.86,0.1)\n",
    "nb_train_score_lst=[] #Preset the Train score list\n",
    "nb_test_score_lst=[] #Preset the Test score list\n",
    "\n",
    "for i in train_size_lst:\n",
    "\n",
    "    #Split the train set, test set, train class, test class\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X, #Predictor Variables\n",
    "                                                     y, #Class labels\n",
    "                                                     stratify=y, #data is split in a stratified fashion, using this as the class labels\n",
    "                                                     test_size=1-i,#Test size is set as 34% of entire set\n",
    "                                                     random_state=28) # Set the randon state for spliting data  in same order\n",
    "\n",
    "   #Set up Naive Bayes classifier with ALL default setting\n",
    "    nbclf = naive_bayes.GaussianNB()\n",
    "    #Plug in the 66% of training set of data\n",
    "    nbclf=nbclf.fit(x_train,y_train)\n",
    "    #Predict y value on testing data\n",
    "    y_pre = nbclf.predict(x_test)\n",
    "\n",
    "    #Calculate the Accuracy Score of the Training and Testing Set\n",
    "    nb_train_score_lst.append(nbclf.score(x_train, y_train))\n",
    "    nb_test_score_lst.append(accuracy_score(y_test, y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.97727272727272729,\n",
       " 0.9838709677419355,\n",
       " 0.97499999999999998,\n",
       " 0.97938144329896903,\n",
       " 0.9826086956521739,\n",
       " 0.98496240601503759,\n",
       " 0.98675496688741726]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_train_score_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9850746268656716,\n",
       " 0.99137931034482762,\n",
       " 0.98979591836734693,\n",
       " 0.97530864197530864,\n",
       " 0.98412698412698407,\n",
       " 1.0,\n",
       " 0.96296296296296291]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_test_score_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DT_train</th>\n",
       "      <th>DT_test</th>\n",
       "      <th>nb_train</th>\n",
       "      <th>nb_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.985075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.870690</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.991379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.989796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.55</th>\n",
       "      <td>0.989691</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.975309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>0.991304</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.984127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.984962</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.986755</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DT_train   DT_test  nb_train   nb_test\n",
       "0.25  0.954545  0.791045  0.977273  0.985075\n",
       "0.35  0.967742  0.870690  0.983871  0.991379\n",
       "0.45  0.987500  0.928571  0.975000  0.989796\n",
       "0.55  0.989691  0.913580  0.979381  0.975309\n",
       "0.65  0.991304  0.952381  0.982609  0.984127\n",
       "0.75  0.992481  0.955556  0.984962  1.000000\n",
       "0.85  0.993377  0.925926  0.986755  0.962963"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(DT_train_score_lst, DT_test_score_lst,nb_train_score_lst,nb_test_score_lst)), \n",
    "             columns = ['DT_train','DT_test','nb_train','nb_test'],\n",
    "            index = np.arange(0.25,0.86,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
